{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep $Q$-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use $Q$-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://github.com/openai/gym). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible actions: 2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Number of possible actions\n",
    "print('Number of possible actions:', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`.  You can see how many actions are possible from `env.action_space.n`, and to get a random action you can use `env.action_space.sample()`.  Passing in an action as an integer to `env.step` will generate the next step in the simulation.  This is general to all Gym games. \n",
    "\n",
    "In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to interact with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [] # actions that the agent selects\n",
    "rewards = [] # obtained rewards\n",
    "state = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()  # choose a random action\n",
    "    state, reward, done, _ = env.step(action) \n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the actions and rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "Rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('Actions:', actions)\n",
    "print('Rewards:', rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each step while the game is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right.\n",
    "\n",
    "## $Q$-Network\n",
    "\n",
    "To keep track of the action values, we'll use a neural network that accepts a state $s$ as input.  The output will be $Q$-values for each available action $a$ (i.e., the output is **all** action values $Q(s,a)$ _corresponding to the input state $s$_).\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "For this Cart-Pole game, the state has four values: the position and velocity of the cart, and the position and velocity of the pole.  Thus, the neural network has **four inputs**, one for each value in the state, and **two outputs**, one for each possible action. \n",
    "\n",
    "As explored in the lesson, to get the training target, we'll first use the context provided by the state $s$ to choose an action $a$, then simulate the game using that action. This will get us the next state, $s'$, and the reward $r$. With that, we can calculate $\\hat{Q}(s,a) = r + \\gamma \\max_{a'}{Q(s', a')}$.  Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "Below is one implementation of the $Q$-network. It uses two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class QNetwork:\n",
    "    def __init__(self, \n",
    "                 learning_rate=0.01, \n",
    "                 state_size=4, \n",
    "                 action_size=2, \n",
    "                 hidden_size=10, \n",
    "                 name='QNetwork'):\n",
    "        # state inputs to the Q-network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "            \n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "            \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, action_size, \n",
    "                                                            activation_fn=None)\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maximum capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Q$-Learning training algorithm\n",
    "\n",
    "We will use the below algorithm to train the network.  For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode $\\leftarrow 1$ **to** $M$ **do**\n",
    "  * Observe $s_0$\n",
    "  * **For** $t \\leftarrow 0$ **to** $T-1$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**\n",
    "\n",
    "You are welcome (and encouraged!) to take the time to extend this code to implement some of the improvements that we discussed in the lesson, to include fixed $Q$ targets, double DQNs, prioritized replay, and/or dueling networks.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcement learning is the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 64               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here we re-initialize the simulation and pre-populate the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 7.0 Training loss: 1.2410 Explore P: 0.9993\n",
      "Episode: 2 Total reward: 27.0 Training loss: 1.1605 Explore P: 0.9966\n",
      "Episode: 3 Total reward: 9.0 Training loss: 1.1894 Explore P: 0.9958\n",
      "Episode: 4 Total reward: 26.0 Training loss: 1.1266 Explore P: 0.9932\n",
      "Episode: 5 Total reward: 9.0 Training loss: 1.1564 Explore P: 0.9923\n",
      "Episode: 6 Total reward: 15.0 Training loss: 1.2599 Explore P: 0.9908\n",
      "Episode: 7 Total reward: 15.0 Training loss: 1.1810 Explore P: 0.9894\n",
      "Episode: 8 Total reward: 40.0 Training loss: 1.3489 Explore P: 0.9855\n",
      "Episode: 9 Total reward: 16.0 Training loss: 1.2255 Explore P: 0.9839\n",
      "Episode: 10 Total reward: 32.0 Training loss: 1.3670 Explore P: 0.9808\n",
      "Episode: 11 Total reward: 18.0 Training loss: 1.2716 Explore P: 0.9790\n",
      "Episode: 12 Total reward: 30.0 Training loss: 1.3966 Explore P: 0.9761\n",
      "Episode: 13 Total reward: 16.0 Training loss: 1.4176 Explore P: 0.9746\n",
      "Episode: 14 Total reward: 9.0 Training loss: 1.5132 Explore P: 0.9737\n",
      "Episode: 15 Total reward: 17.0 Training loss: 1.5641 Explore P: 0.9721\n",
      "Episode: 16 Total reward: 19.0 Training loss: 1.3598 Explore P: 0.9703\n",
      "Episode: 17 Total reward: 12.0 Training loss: 1.4353 Explore P: 0.9691\n",
      "Episode: 18 Total reward: 17.0 Training loss: 1.6180 Explore P: 0.9675\n",
      "Episode: 19 Total reward: 9.0 Training loss: 1.3444 Explore P: 0.9666\n",
      "Episode: 20 Total reward: 13.0 Training loss: 1.5809 Explore P: 0.9654\n",
      "Episode: 21 Total reward: 28.0 Training loss: 1.6494 Explore P: 0.9627\n",
      "Episode: 22 Total reward: 45.0 Training loss: 2.5054 Explore P: 0.9584\n",
      "Episode: 23 Total reward: 10.0 Training loss: 1.9017 Explore P: 0.9575\n",
      "Episode: 24 Total reward: 56.0 Training loss: 2.5629 Explore P: 0.9522\n",
      "Episode: 25 Total reward: 9.0 Training loss: 2.0491 Explore P: 0.9513\n",
      "Episode: 26 Total reward: 9.0 Training loss: 1.9494 Explore P: 0.9505\n",
      "Episode: 27 Total reward: 13.0 Training loss: 2.2052 Explore P: 0.9493\n",
      "Episode: 28 Total reward: 19.0 Training loss: 4.1628 Explore P: 0.9475\n",
      "Episode: 29 Total reward: 13.0 Training loss: 2.7750 Explore P: 0.9463\n",
      "Episode: 30 Total reward: 17.0 Training loss: 3.8404 Explore P: 0.9447\n",
      "Episode: 31 Total reward: 13.0 Training loss: 4.8037 Explore P: 0.9435\n",
      "Episode: 32 Total reward: 7.0 Training loss: 3.0174 Explore P: 0.9428\n",
      "Episode: 33 Total reward: 16.0 Training loss: 2.8043 Explore P: 0.9413\n",
      "Episode: 34 Total reward: 10.0 Training loss: 4.5738 Explore P: 0.9404\n",
      "Episode: 35 Total reward: 21.0 Training loss: 2.9246 Explore P: 0.9384\n",
      "Episode: 36 Total reward: 16.0 Training loss: 6.1022 Explore P: 0.9370\n",
      "Episode: 37 Total reward: 17.0 Training loss: 6.1613 Explore P: 0.9354\n",
      "Episode: 38 Total reward: 10.0 Training loss: 3.3650 Explore P: 0.9345\n",
      "Episode: 39 Total reward: 18.0 Training loss: 6.9180 Explore P: 0.9328\n",
      "Episode: 40 Total reward: 27.0 Training loss: 3.3514 Explore P: 0.9303\n",
      "Episode: 41 Total reward: 19.0 Training loss: 11.6754 Explore P: 0.9286\n",
      "Episode: 42 Total reward: 20.0 Training loss: 18.3206 Explore P: 0.9267\n",
      "Episode: 43 Total reward: 14.0 Training loss: 5.6188 Explore P: 0.9254\n",
      "Episode: 44 Total reward: 13.0 Training loss: 11.1272 Explore P: 0.9243\n",
      "Episode: 45 Total reward: 9.0 Training loss: 11.0162 Explore P: 0.9234\n",
      "Episode: 46 Total reward: 11.0 Training loss: 4.7649 Explore P: 0.9224\n",
      "Episode: 47 Total reward: 29.0 Training loss: 25.0283 Explore P: 0.9198\n",
      "Episode: 48 Total reward: 21.0 Training loss: 5.5415 Explore P: 0.9179\n",
      "Episode: 49 Total reward: 12.0 Training loss: 12.9774 Explore P: 0.9168\n",
      "Episode: 50 Total reward: 16.0 Training loss: 16.0771 Explore P: 0.9153\n",
      "Episode: 51 Total reward: 17.0 Training loss: 9.5263 Explore P: 0.9138\n",
      "Episode: 52 Total reward: 14.0 Training loss: 7.3965 Explore P: 0.9125\n",
      "Episode: 53 Total reward: 16.0 Training loss: 17.6443 Explore P: 0.9111\n",
      "Episode: 54 Total reward: 12.0 Training loss: 23.0048 Explore P: 0.9100\n",
      "Episode: 55 Total reward: 12.0 Training loss: 22.6612 Explore P: 0.9089\n",
      "Episode: 56 Total reward: 20.0 Training loss: 38.9313 Explore P: 0.9071\n",
      "Episode: 57 Total reward: 17.0 Training loss: 6.9394 Explore P: 0.9056\n",
      "Episode: 58 Total reward: 17.0 Training loss: 24.0915 Explore P: 0.9041\n",
      "Episode: 59 Total reward: 13.0 Training loss: 23.0700 Explore P: 0.9029\n",
      "Episode: 60 Total reward: 12.0 Training loss: 30.6664 Explore P: 0.9019\n",
      "Episode: 61 Total reward: 28.0 Training loss: 61.6678 Explore P: 0.8994\n",
      "Episode: 62 Total reward: 8.0 Training loss: 46.8780 Explore P: 0.8987\n",
      "Episode: 63 Total reward: 9.0 Training loss: 9.9978 Explore P: 0.8979\n",
      "Episode: 64 Total reward: 30.0 Training loss: 40.8217 Explore P: 0.8952\n",
      "Episode: 65 Total reward: 15.0 Training loss: 10.1545 Explore P: 0.8939\n",
      "Episode: 66 Total reward: 38.0 Training loss: 34.2319 Explore P: 0.8905\n",
      "Episode: 67 Total reward: 14.0 Training loss: 31.2833 Explore P: 0.8893\n",
      "Episode: 68 Total reward: 10.0 Training loss: 67.4579 Explore P: 0.8884\n",
      "Episode: 69 Total reward: 18.0 Training loss: 10.8347 Explore P: 0.8868\n",
      "Episode: 70 Total reward: 15.0 Training loss: 8.9636 Explore P: 0.8855\n",
      "Episode: 71 Total reward: 13.0 Training loss: 6.9816 Explore P: 0.8844\n",
      "Episode: 72 Total reward: 15.0 Training loss: 30.7365 Explore P: 0.8831\n",
      "Episode: 73 Total reward: 13.0 Training loss: 21.2117 Explore P: 0.8819\n",
      "Episode: 74 Total reward: 10.0 Training loss: 23.8622 Explore P: 0.8811\n",
      "Episode: 75 Total reward: 17.0 Training loss: 64.0910 Explore P: 0.8796\n",
      "Episode: 76 Total reward: 27.0 Training loss: 33.5723 Explore P: 0.8772\n",
      "Episode: 77 Total reward: 9.0 Training loss: 8.5274 Explore P: 0.8765\n",
      "Episode: 78 Total reward: 11.0 Training loss: 37.3870 Explore P: 0.8755\n",
      "Episode: 79 Total reward: 24.0 Training loss: 71.5791 Explore P: 0.8734\n",
      "Episode: 80 Total reward: 15.0 Training loss: 11.5783 Explore P: 0.8721\n",
      "Episode: 81 Total reward: 20.0 Training loss: 112.4519 Explore P: 0.8704\n",
      "Episode: 82 Total reward: 23.0 Training loss: 47.3828 Explore P: 0.8684\n",
      "Episode: 83 Total reward: 16.0 Training loss: 12.3084 Explore P: 0.8671\n",
      "Episode: 84 Total reward: 14.0 Training loss: 41.8522 Explore P: 0.8659\n",
      "Episode: 85 Total reward: 39.0 Training loss: 13.0413 Explore P: 0.8625\n",
      "Episode: 86 Total reward: 34.0 Training loss: 113.2186 Explore P: 0.8596\n",
      "Episode: 87 Total reward: 24.0 Training loss: 10.4398 Explore P: 0.8576\n",
      "Episode: 88 Total reward: 9.0 Training loss: 141.2001 Explore P: 0.8568\n",
      "Episode: 89 Total reward: 17.0 Training loss: 33.9570 Explore P: 0.8554\n",
      "Episode: 90 Total reward: 39.0 Training loss: 220.2964 Explore P: 0.8521\n",
      "Episode: 91 Total reward: 12.0 Training loss: 10.7083 Explore P: 0.8511\n",
      "Episode: 92 Total reward: 13.0 Training loss: 208.5661 Explore P: 0.8500\n",
      "Episode: 93 Total reward: 24.0 Training loss: 68.3135 Explore P: 0.8480\n",
      "Episode: 94 Total reward: 20.0 Training loss: 150.2342 Explore P: 0.8463\n",
      "Episode: 95 Total reward: 14.0 Training loss: 173.9394 Explore P: 0.8451\n",
      "Episode: 96 Total reward: 16.0 Training loss: 146.9202 Explore P: 0.8438\n",
      "Episode: 97 Total reward: 12.0 Training loss: 231.7186 Explore P: 0.8428\n",
      "Episode: 98 Total reward: 15.0 Training loss: 86.8469 Explore P: 0.8416\n",
      "Episode: 99 Total reward: 21.0 Training loss: 155.9241 Explore P: 0.8398\n",
      "Episode: 100 Total reward: 12.0 Training loss: 109.0019 Explore P: 0.8388\n",
      "Episode: 101 Total reward: 9.0 Training loss: 13.2932 Explore P: 0.8381\n",
      "Episode: 102 Total reward: 8.0 Training loss: 166.4994 Explore P: 0.8374\n",
      "Episode: 103 Total reward: 23.0 Training loss: 137.9450 Explore P: 0.8355\n",
      "Episode: 104 Total reward: 11.0 Training loss: 219.4705 Explore P: 0.8346\n",
      "Episode: 105 Total reward: 45.0 Training loss: 12.7051 Explore P: 0.8309\n",
      "Episode: 106 Total reward: 31.0 Training loss: 17.0416 Explore P: 0.8284\n",
      "Episode: 107 Total reward: 20.0 Training loss: 44.7629 Explore P: 0.8267\n",
      "Episode: 108 Total reward: 14.0 Training loss: 13.4668 Explore P: 0.8256\n",
      "Episode: 109 Total reward: 47.0 Training loss: 87.0070 Explore P: 0.8218\n",
      "Episode: 110 Total reward: 28.0 Training loss: 45.4449 Explore P: 0.8195\n",
      "Episode: 111 Total reward: 20.0 Training loss: 19.7811 Explore P: 0.8179\n",
      "Episode: 112 Total reward: 23.0 Training loss: 12.4465 Explore P: 0.8160\n",
      "Episode: 113 Total reward: 25.0 Training loss: 12.6463 Explore P: 0.8140\n",
      "Episode: 114 Total reward: 12.0 Training loss: 202.2171 Explore P: 0.8130\n",
      "Episode: 115 Total reward: 15.0 Training loss: 22.7712 Explore P: 0.8118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 116 Total reward: 16.0 Training loss: 17.3196 Explore P: 0.8106\n",
      "Episode: 117 Total reward: 15.0 Training loss: 165.2392 Explore P: 0.8094\n",
      "Episode: 118 Total reward: 10.0 Training loss: 217.5583 Explore P: 0.8086\n",
      "Episode: 119 Total reward: 29.0 Training loss: 20.5309 Explore P: 0.8062\n",
      "Episode: 120 Total reward: 27.0 Training loss: 92.2815 Explore P: 0.8041\n",
      "Episode: 121 Total reward: 20.0 Training loss: 151.8878 Explore P: 0.8025\n",
      "Episode: 122 Total reward: 19.0 Training loss: 12.1043 Explore P: 0.8010\n",
      "Episode: 123 Total reward: 18.0 Training loss: 78.7951 Explore P: 0.7996\n",
      "Episode: 124 Total reward: 27.0 Training loss: 227.2028 Explore P: 0.7975\n",
      "Episode: 125 Total reward: 16.0 Training loss: 92.7841 Explore P: 0.7962\n",
      "Episode: 126 Total reward: 35.0 Training loss: 76.7857 Explore P: 0.7934\n",
      "Episode: 127 Total reward: 14.0 Training loss: 222.2552 Explore P: 0.7924\n",
      "Episode: 128 Total reward: 12.0 Training loss: 71.8739 Explore P: 0.7914\n",
      "Episode: 129 Total reward: 24.0 Training loss: 74.1252 Explore P: 0.7895\n",
      "Episode: 130 Total reward: 17.0 Training loss: 20.1293 Explore P: 0.7882\n",
      "Episode: 131 Total reward: 12.0 Training loss: 72.3258 Explore P: 0.7873\n",
      "Episode: 132 Total reward: 41.0 Training loss: 242.7564 Explore P: 0.7841\n",
      "Episode: 133 Total reward: 47.0 Training loss: 287.9419 Explore P: 0.7805\n",
      "Episode: 134 Total reward: 14.0 Training loss: 126.4303 Explore P: 0.7794\n",
      "Episode: 135 Total reward: 12.0 Training loss: 195.0080 Explore P: 0.7785\n",
      "Episode: 136 Total reward: 17.0 Training loss: 10.6855 Explore P: 0.7772\n",
      "Episode: 137 Total reward: 8.0 Training loss: 73.6540 Explore P: 0.7766\n",
      "Episode: 138 Total reward: 16.0 Training loss: 191.2928 Explore P: 0.7753\n",
      "Episode: 139 Total reward: 14.0 Training loss: 88.8967 Explore P: 0.7743\n",
      "Episode: 140 Total reward: 30.0 Training loss: 295.4264 Explore P: 0.7720\n",
      "Episode: 141 Total reward: 14.0 Training loss: 17.5565 Explore P: 0.7709\n",
      "Episode: 142 Total reward: 22.0 Training loss: 216.8226 Explore P: 0.7692\n",
      "Episode: 143 Total reward: 37.0 Training loss: 113.2873 Explore P: 0.7664\n",
      "Episode: 144 Total reward: 19.0 Training loss: 451.8492 Explore P: 0.7650\n",
      "Episode: 145 Total reward: 18.0 Training loss: 364.7983 Explore P: 0.7636\n",
      "Episode: 146 Total reward: 15.0 Training loss: 14.5341 Explore P: 0.7625\n",
      "Episode: 147 Total reward: 10.0 Training loss: 172.8927 Explore P: 0.7618\n",
      "Episode: 148 Total reward: 14.0 Training loss: 217.5798 Explore P: 0.7607\n",
      "Episode: 149 Total reward: 13.0 Training loss: 9.4601 Explore P: 0.7597\n",
      "Episode: 150 Total reward: 22.0 Training loss: 15.5531 Explore P: 0.7581\n",
      "Episode: 151 Total reward: 15.0 Training loss: 13.1613 Explore P: 0.7570\n",
      "Episode: 152 Total reward: 17.0 Training loss: 199.5231 Explore P: 0.7557\n",
      "Episode: 153 Total reward: 41.0 Training loss: 132.2392 Explore P: 0.7526\n",
      "Episode: 154 Total reward: 36.0 Training loss: 127.9302 Explore P: 0.7500\n",
      "Episode: 155 Total reward: 13.0 Training loss: 91.9970 Explore P: 0.7490\n",
      "Episode: 156 Total reward: 35.0 Training loss: 101.4064 Explore P: 0.7464\n",
      "Episode: 157 Total reward: 16.0 Training loss: 10.1194 Explore P: 0.7452\n",
      "Episode: 158 Total reward: 16.0 Training loss: 184.8770 Explore P: 0.7441\n",
      "Episode: 159 Total reward: 29.0 Training loss: 117.5018 Explore P: 0.7419\n",
      "Episode: 160 Total reward: 16.0 Training loss: 105.1702 Explore P: 0.7408\n",
      "Episode: 161 Total reward: 38.0 Training loss: 101.1143 Explore P: 0.7380\n",
      "Episode: 162 Total reward: 23.0 Training loss: 8.6866 Explore P: 0.7363\n",
      "Episode: 163 Total reward: 13.0 Training loss: 263.8106 Explore P: 0.7354\n",
      "Episode: 164 Total reward: 51.0 Training loss: 7.5163 Explore P: 0.7317\n",
      "Episode: 165 Total reward: 38.0 Training loss: 368.7135 Explore P: 0.7290\n",
      "Episode: 166 Total reward: 27.0 Training loss: 125.9313 Explore P: 0.7270\n",
      "Episode: 167 Total reward: 41.0 Training loss: 8.3137 Explore P: 0.7241\n",
      "Episode: 168 Total reward: 12.0 Training loss: 233.8109 Explore P: 0.7232\n",
      "Episode: 169 Total reward: 12.0 Training loss: 7.2431 Explore P: 0.7224\n",
      "Episode: 170 Total reward: 37.0 Training loss: 10.4388 Explore P: 0.7197\n",
      "Episode: 171 Total reward: 9.0 Training loss: 149.0851 Explore P: 0.7191\n",
      "Episode: 172 Total reward: 10.0 Training loss: 96.5836 Explore P: 0.7184\n",
      "Episode: 173 Total reward: 11.0 Training loss: 109.2574 Explore P: 0.7176\n",
      "Episode: 174 Total reward: 10.0 Training loss: 6.9834 Explore P: 0.7169\n",
      "Episode: 175 Total reward: 33.0 Training loss: 7.5654 Explore P: 0.7146\n",
      "Episode: 176 Total reward: 22.0 Training loss: 309.4824 Explore P: 0.7130\n",
      "Episode: 177 Total reward: 14.0 Training loss: 97.9796 Explore P: 0.7121\n",
      "Episode: 178 Total reward: 13.0 Training loss: 7.2587 Explore P: 0.7111\n",
      "Episode: 179 Total reward: 8.0 Training loss: 6.3616 Explore P: 0.7106\n",
      "Episode: 180 Total reward: 15.0 Training loss: 164.1653 Explore P: 0.7095\n",
      "Episode: 181 Total reward: 11.0 Training loss: 104.6321 Explore P: 0.7088\n",
      "Episode: 182 Total reward: 11.0 Training loss: 6.4513 Explore P: 0.7080\n",
      "Episode: 183 Total reward: 11.0 Training loss: 294.7428 Explore P: 0.7072\n",
      "Episode: 184 Total reward: 30.0 Training loss: 106.1564 Explore P: 0.7051\n",
      "Episode: 185 Total reward: 19.0 Training loss: 229.8553 Explore P: 0.7038\n",
      "Episode: 186 Total reward: 12.0 Training loss: 158.1501 Explore P: 0.7030\n",
      "Episode: 187 Total reward: 33.0 Training loss: 90.5710 Explore P: 0.7007\n",
      "Episode: 188 Total reward: 28.0 Training loss: 4.6707 Explore P: 0.6988\n",
      "Episode: 189 Total reward: 11.0 Training loss: 4.5323 Explore P: 0.6980\n",
      "Episode: 190 Total reward: 8.0 Training loss: 245.1872 Explore P: 0.6975\n",
      "Episode: 191 Total reward: 13.0 Training loss: 7.0984 Explore P: 0.6966\n",
      "Episode: 192 Total reward: 16.0 Training loss: 7.3356 Explore P: 0.6955\n",
      "Episode: 193 Total reward: 21.0 Training loss: 5.3391 Explore P: 0.6940\n",
      "Episode: 194 Total reward: 8.0 Training loss: 351.3446 Explore P: 0.6935\n",
      "Episode: 195 Total reward: 19.0 Training loss: 403.7181 Explore P: 0.6922\n",
      "Episode: 196 Total reward: 38.0 Training loss: 102.9632 Explore P: 0.6896\n",
      "Episode: 197 Total reward: 15.0 Training loss: 199.4246 Explore P: 0.6886\n",
      "Episode: 198 Total reward: 9.0 Training loss: 3.7785 Explore P: 0.6880\n",
      "Episode: 199 Total reward: 15.0 Training loss: 3.7838 Explore P: 0.6870\n",
      "Episode: 200 Total reward: 33.0 Training loss: 3.2681 Explore P: 0.6847\n",
      "Episode: 201 Total reward: 18.0 Training loss: 77.7659 Explore P: 0.6835\n",
      "Episode: 202 Total reward: 19.0 Training loss: 152.4286 Explore P: 0.6822\n",
      "Episode: 203 Total reward: 26.0 Training loss: 191.0512 Explore P: 0.6805\n",
      "Episode: 204 Total reward: 10.0 Training loss: 139.0753 Explore P: 0.6798\n",
      "Episode: 205 Total reward: 17.0 Training loss: 3.2221 Explore P: 0.6787\n",
      "Episode: 206 Total reward: 8.0 Training loss: 286.3316 Explore P: 0.6781\n",
      "Episode: 207 Total reward: 11.0 Training loss: 184.6141 Explore P: 0.6774\n",
      "Episode: 208 Total reward: 10.0 Training loss: 2.1179 Explore P: 0.6767\n",
      "Episode: 209 Total reward: 13.0 Training loss: 85.2980 Explore P: 0.6759\n",
      "Episode: 210 Total reward: 19.0 Training loss: 1.7438 Explore P: 0.6746\n",
      "Episode: 211 Total reward: 36.0 Training loss: 111.2224 Explore P: 0.6722\n",
      "Episode: 212 Total reward: 13.0 Training loss: 311.2894 Explore P: 0.6714\n",
      "Episode: 213 Total reward: 18.0 Training loss: 2.7700 Explore P: 0.6702\n",
      "Episode: 214 Total reward: 11.0 Training loss: 1.4641 Explore P: 0.6694\n",
      "Episode: 215 Total reward: 13.0 Training loss: 115.1166 Explore P: 0.6686\n",
      "Episode: 216 Total reward: 8.0 Training loss: 61.5081 Explore P: 0.6681\n",
      "Episode: 217 Total reward: 10.0 Training loss: 216.8546 Explore P: 0.6674\n",
      "Episode: 218 Total reward: 9.0 Training loss: 147.5374 Explore P: 0.6668\n",
      "Episode: 219 Total reward: 8.0 Training loss: 211.1869 Explore P: 0.6663\n",
      "Episode: 220 Total reward: 27.0 Training loss: 77.3184 Explore P: 0.6645\n",
      "Episode: 221 Total reward: 19.0 Training loss: 1.3549 Explore P: 0.6633\n",
      "Episode: 222 Total reward: 10.0 Training loss: 168.3000 Explore P: 0.6626\n",
      "Episode: 223 Total reward: 18.0 Training loss: 240.4009 Explore P: 0.6615\n",
      "Episode: 224 Total reward: 9.0 Training loss: 60.5632 Explore P: 0.6609\n",
      "Episode: 225 Total reward: 10.0 Training loss: 70.4327 Explore P: 0.6602\n",
      "Episode: 226 Total reward: 12.0 Training loss: 117.9275 Explore P: 0.6594\n",
      "Episode: 227 Total reward: 9.0 Training loss: 1.6889 Explore P: 0.6589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 228 Total reward: 20.0 Training loss: 1.1571 Explore P: 0.6576\n",
      "Episode: 229 Total reward: 11.0 Training loss: 1.4042 Explore P: 0.6568\n",
      "Episode: 230 Total reward: 10.0 Training loss: 106.6835 Explore P: 0.6562\n",
      "Episode: 231 Total reward: 11.0 Training loss: 72.8743 Explore P: 0.6555\n",
      "Episode: 232 Total reward: 16.0 Training loss: 199.1070 Explore P: 0.6545\n",
      "Episode: 233 Total reward: 26.0 Training loss: 2.5761 Explore P: 0.6528\n",
      "Episode: 234 Total reward: 8.0 Training loss: 56.3979 Explore P: 0.6523\n",
      "Episode: 235 Total reward: 13.0 Training loss: 56.8964 Explore P: 0.6514\n",
      "Episode: 236 Total reward: 10.0 Training loss: 122.6433 Explore P: 0.6508\n",
      "Episode: 237 Total reward: 11.0 Training loss: 71.7571 Explore P: 0.6501\n",
      "Episode: 238 Total reward: 10.0 Training loss: 146.3111 Explore P: 0.6494\n",
      "Episode: 239 Total reward: 10.0 Training loss: 1.7926 Explore P: 0.6488\n",
      "Episode: 240 Total reward: 12.0 Training loss: 1.0416 Explore P: 0.6480\n",
      "Episode: 241 Total reward: 9.0 Training loss: 52.4296 Explore P: 0.6475\n",
      "Episode: 242 Total reward: 10.0 Training loss: 106.4514 Explore P: 0.6468\n",
      "Episode: 243 Total reward: 15.0 Training loss: 41.7377 Explore P: 0.6459\n",
      "Episode: 244 Total reward: 11.0 Training loss: 1.5837 Explore P: 0.6452\n",
      "Episode: 245 Total reward: 17.0 Training loss: 106.8884 Explore P: 0.6441\n",
      "Episode: 246 Total reward: 20.0 Training loss: 122.9217 Explore P: 0.6428\n",
      "Episode: 247 Total reward: 19.0 Training loss: 1.2479 Explore P: 0.6416\n",
      "Episode: 248 Total reward: 11.0 Training loss: 1.4845 Explore P: 0.6409\n",
      "Episode: 249 Total reward: 9.0 Training loss: 39.9257 Explore P: 0.6404\n",
      "Episode: 250 Total reward: 10.0 Training loss: 49.3157 Explore P: 0.6397\n",
      "Episode: 251 Total reward: 10.0 Training loss: 106.6120 Explore P: 0.6391\n",
      "Episode: 252 Total reward: 9.0 Training loss: 46.5135 Explore P: 0.6385\n",
      "Episode: 253 Total reward: 10.0 Training loss: 85.9010 Explore P: 0.6379\n",
      "Episode: 254 Total reward: 13.0 Training loss: 92.3903 Explore P: 0.6371\n",
      "Episode: 255 Total reward: 9.0 Training loss: 1.5539 Explore P: 0.6365\n",
      "Episode: 256 Total reward: 10.0 Training loss: 57.9514 Explore P: 0.6359\n",
      "Episode: 257 Total reward: 21.0 Training loss: 0.9389 Explore P: 0.6346\n",
      "Episode: 258 Total reward: 10.0 Training loss: 0.7573 Explore P: 0.6340\n",
      "Episode: 259 Total reward: 19.0 Training loss: 79.2859 Explore P: 0.6328\n",
      "Episode: 260 Total reward: 10.0 Training loss: 56.7963 Explore P: 0.6322\n",
      "Episode: 261 Total reward: 22.0 Training loss: 33.3947 Explore P: 0.6308\n",
      "Episode: 262 Total reward: 8.0 Training loss: 93.6956 Explore P: 0.6303\n",
      "Episode: 263 Total reward: 9.0 Training loss: 79.1496 Explore P: 0.6297\n",
      "Episode: 264 Total reward: 10.0 Training loss: 83.3561 Explore P: 0.6291\n",
      "Episode: 265 Total reward: 8.0 Training loss: 1.4969 Explore P: 0.6286\n",
      "Episode: 266 Total reward: 14.0 Training loss: 105.7235 Explore P: 0.6278\n",
      "Episode: 267 Total reward: 10.0 Training loss: 31.5769 Explore P: 0.6271\n",
      "Episode: 268 Total reward: 9.0 Training loss: 2.0226 Explore P: 0.6266\n",
      "Episode: 269 Total reward: 17.0 Training loss: 0.9085 Explore P: 0.6255\n",
      "Episode: 270 Total reward: 15.0 Training loss: 1.6901 Explore P: 0.6246\n",
      "Episode: 271 Total reward: 11.0 Training loss: 75.7025 Explore P: 0.6239\n",
      "Episode: 272 Total reward: 11.0 Training loss: 273.4335 Explore P: 0.6233\n",
      "Episode: 273 Total reward: 16.0 Training loss: 1.8353 Explore P: 0.6223\n",
      "Episode: 274 Total reward: 17.0 Training loss: 50.6243 Explore P: 0.6212\n",
      "Episode: 275 Total reward: 13.0 Training loss: 181.9086 Explore P: 0.6205\n",
      "Episode: 276 Total reward: 24.0 Training loss: 34.2895 Explore P: 0.6190\n",
      "Episode: 277 Total reward: 11.0 Training loss: 1.4760 Explore P: 0.6183\n",
      "Episode: 278 Total reward: 13.0 Training loss: 32.7546 Explore P: 0.6175\n",
      "Episode: 279 Total reward: 10.0 Training loss: 2.0591 Explore P: 0.6169\n",
      "Episode: 280 Total reward: 9.0 Training loss: 107.3667 Explore P: 0.6164\n",
      "Episode: 281 Total reward: 14.0 Training loss: 27.8967 Explore P: 0.6155\n",
      "Episode: 282 Total reward: 12.0 Training loss: 70.6477 Explore P: 0.6148\n",
      "Episode: 283 Total reward: 12.0 Training loss: 165.9540 Explore P: 0.6141\n",
      "Episode: 284 Total reward: 10.0 Training loss: 146.1571 Explore P: 0.6135\n",
      "Episode: 285 Total reward: 11.0 Training loss: 27.3833 Explore P: 0.6128\n",
      "Episode: 286 Total reward: 9.0 Training loss: 36.0100 Explore P: 0.6123\n",
      "Episode: 287 Total reward: 15.0 Training loss: 1.7474 Explore P: 0.6114\n",
      "Episode: 288 Total reward: 15.0 Training loss: 1.4443 Explore P: 0.6105\n",
      "Episode: 289 Total reward: 10.0 Training loss: 115.2501 Explore P: 0.6099\n",
      "Episode: 290 Total reward: 9.0 Training loss: 67.5595 Explore P: 0.6093\n",
      "Episode: 291 Total reward: 13.0 Training loss: 71.2229 Explore P: 0.6085\n",
      "Episode: 292 Total reward: 17.0 Training loss: 23.9118 Explore P: 0.6075\n",
      "Episode: 293 Total reward: 15.0 Training loss: 66.7561 Explore P: 0.6066\n",
      "Episode: 294 Total reward: 37.0 Training loss: 96.8665 Explore P: 0.6044\n",
      "Episode: 295 Total reward: 12.0 Training loss: 1.0517 Explore P: 0.6037\n",
      "Episode: 296 Total reward: 8.0 Training loss: 2.1084 Explore P: 0.6032\n",
      "Episode: 297 Total reward: 11.0 Training loss: 66.5293 Explore P: 0.6026\n",
      "Episode: 298 Total reward: 8.0 Training loss: 139.2704 Explore P: 0.6021\n",
      "Episode: 299 Total reward: 14.0 Training loss: 2.2436 Explore P: 0.6013\n",
      "Episode: 300 Total reward: 8.0 Training loss: 96.2238 Explore P: 0.6008\n",
      "Episode: 301 Total reward: 9.0 Training loss: 38.9052 Explore P: 0.6003\n",
      "Episode: 302 Total reward: 28.0 Training loss: 73.0310 Explore P: 0.5986\n",
      "Episode: 303 Total reward: 26.0 Training loss: 1.8735 Explore P: 0.5971\n",
      "Episode: 304 Total reward: 13.0 Training loss: 1.8434 Explore P: 0.5963\n",
      "Episode: 305 Total reward: 11.0 Training loss: 58.1135 Explore P: 0.5957\n",
      "Episode: 306 Total reward: 17.0 Training loss: 1.5271 Explore P: 0.5947\n",
      "Episode: 307 Total reward: 19.0 Training loss: 26.1751 Explore P: 0.5936\n",
      "Episode: 308 Total reward: 8.0 Training loss: 84.4778 Explore P: 0.5931\n",
      "Episode: 309 Total reward: 11.0 Training loss: 1.5463 Explore P: 0.5925\n",
      "Episode: 310 Total reward: 10.0 Training loss: 57.1567 Explore P: 0.5919\n",
      "Episode: 311 Total reward: 13.0 Training loss: 1.7911 Explore P: 0.5911\n",
      "Episode: 312 Total reward: 10.0 Training loss: 1.2147 Explore P: 0.5906\n",
      "Episode: 313 Total reward: 9.0 Training loss: 52.7048 Explore P: 0.5900\n",
      "Episode: 314 Total reward: 11.0 Training loss: 56.1833 Explore P: 0.5894\n",
      "Episode: 315 Total reward: 12.0 Training loss: 21.0824 Explore P: 0.5887\n",
      "Episode: 316 Total reward: 12.0 Training loss: 55.5913 Explore P: 0.5880\n",
      "Episode: 317 Total reward: 10.0 Training loss: 112.5708 Explore P: 0.5874\n",
      "Episode: 318 Total reward: 11.0 Training loss: 39.7455 Explore P: 0.5868\n",
      "Episode: 319 Total reward: 19.0 Training loss: 19.8236 Explore P: 0.5857\n",
      "Episode: 320 Total reward: 10.0 Training loss: 43.9618 Explore P: 0.5851\n",
      "Episode: 321 Total reward: 13.0 Training loss: 114.7300 Explore P: 0.5844\n",
      "Episode: 322 Total reward: 12.0 Training loss: 69.6151 Explore P: 0.5837\n",
      "Episode: 323 Total reward: 29.0 Training loss: 1.0073 Explore P: 0.5820\n",
      "Episode: 324 Total reward: 18.0 Training loss: 124.0225 Explore P: 0.5810\n",
      "Episode: 325 Total reward: 10.0 Training loss: 51.0043 Explore P: 0.5804\n",
      "Episode: 326 Total reward: 10.0 Training loss: 50.6658 Explore P: 0.5799\n",
      "Episode: 327 Total reward: 24.0 Training loss: 55.8050 Explore P: 0.5785\n",
      "Episode: 328 Total reward: 26.0 Training loss: 16.4484 Explore P: 0.5770\n",
      "Episode: 329 Total reward: 16.0 Training loss: 49.2561 Explore P: 0.5761\n",
      "Episode: 330 Total reward: 12.0 Training loss: 1.5861 Explore P: 0.5754\n",
      "Episode: 331 Total reward: 15.0 Training loss: 16.4084 Explore P: 0.5746\n",
      "Episode: 332 Total reward: 8.0 Training loss: 1.4823 Explore P: 0.5741\n",
      "Episode: 333 Total reward: 9.0 Training loss: 31.5499 Explore P: 0.5736\n",
      "Episode: 334 Total reward: 10.0 Training loss: 79.3802 Explore P: 0.5731\n",
      "Episode: 335 Total reward: 22.0 Training loss: 17.0118 Explore P: 0.5718\n",
      "Episode: 336 Total reward: 28.0 Training loss: 48.6717 Explore P: 0.5703\n",
      "Episode: 337 Total reward: 15.0 Training loss: 1.0378 Explore P: 0.5694\n",
      "Episode: 338 Total reward: 22.0 Training loss: 1.1252 Explore P: 0.5682\n",
      "Episode: 339 Total reward: 26.0 Training loss: 57.2034 Explore P: 0.5667\n",
      "Episode: 340 Total reward: 11.0 Training loss: 92.6017 Explore P: 0.5661\n",
      "Episode: 341 Total reward: 14.0 Training loss: 19.0794 Explore P: 0.5654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 342 Total reward: 18.0 Training loss: 0.9782 Explore P: 0.5644\n",
      "Episode: 343 Total reward: 26.0 Training loss: 42.3544 Explore P: 0.5629\n",
      "Episode: 344 Total reward: 13.0 Training loss: 13.6129 Explore P: 0.5622\n",
      "Episode: 345 Total reward: 11.0 Training loss: 81.2144 Explore P: 0.5616\n",
      "Episode: 346 Total reward: 7.0 Training loss: 90.6157 Explore P: 0.5612\n",
      "Episode: 347 Total reward: 17.0 Training loss: 38.0204 Explore P: 0.5603\n",
      "Episode: 348 Total reward: 9.0 Training loss: 30.5523 Explore P: 0.5598\n",
      "Episode: 349 Total reward: 40.0 Training loss: 77.2698 Explore P: 0.5576\n",
      "Episode: 350 Total reward: 26.0 Training loss: 21.5425 Explore P: 0.5562\n",
      "Episode: 351 Total reward: 32.0 Training loss: 14.8343 Explore P: 0.5544\n",
      "Episode: 352 Total reward: 8.0 Training loss: 13.7864 Explore P: 0.5540\n",
      "Episode: 353 Total reward: 11.0 Training loss: 26.8809 Explore P: 0.5534\n",
      "Episode: 354 Total reward: 9.0 Training loss: 1.2051 Explore P: 0.5529\n",
      "Episode: 355 Total reward: 23.0 Training loss: 37.4133 Explore P: 0.5516\n",
      "Episode: 356 Total reward: 16.0 Training loss: 34.7134 Explore P: 0.5508\n",
      "Episode: 357 Total reward: 12.0 Training loss: 14.6231 Explore P: 0.5501\n",
      "Episode: 358 Total reward: 15.0 Training loss: 1.0906 Explore P: 0.5493\n",
      "Episode: 359 Total reward: 15.0 Training loss: 0.8192 Explore P: 0.5485\n",
      "Episode: 360 Total reward: 9.0 Training loss: 37.6915 Explore P: 0.5480\n",
      "Episode: 361 Total reward: 12.0 Training loss: 33.4887 Explore P: 0.5474\n",
      "Episode: 362 Total reward: 10.0 Training loss: 1.0074 Explore P: 0.5468\n",
      "Episode: 363 Total reward: 32.0 Training loss: 24.0134 Explore P: 0.5451\n",
      "Episode: 364 Total reward: 25.0 Training loss: 11.3366 Explore P: 0.5438\n",
      "Episode: 365 Total reward: 9.0 Training loss: 10.9197 Explore P: 0.5433\n",
      "Episode: 366 Total reward: 11.0 Training loss: 11.6874 Explore P: 0.5427\n",
      "Episode: 367 Total reward: 27.0 Training loss: 13.5044 Explore P: 0.5413\n",
      "Episode: 368 Total reward: 19.0 Training loss: 12.9138 Explore P: 0.5403\n",
      "Episode: 369 Total reward: 13.0 Training loss: 55.1504 Explore P: 0.5396\n",
      "Episode: 370 Total reward: 10.0 Training loss: 1.3851 Explore P: 0.5391\n",
      "Episode: 371 Total reward: 11.0 Training loss: 37.6166 Explore P: 0.5385\n",
      "Episode: 372 Total reward: 15.0 Training loss: 23.6193 Explore P: 0.5377\n",
      "Episode: 373 Total reward: 11.0 Training loss: 72.1313 Explore P: 0.5371\n",
      "Episode: 374 Total reward: 15.0 Training loss: 67.6196 Explore P: 0.5363\n",
      "Episode: 375 Total reward: 15.0 Training loss: 29.9246 Explore P: 0.5355\n",
      "Episode: 376 Total reward: 13.0 Training loss: 30.6666 Explore P: 0.5348\n",
      "Episode: 377 Total reward: 12.0 Training loss: 51.5421 Explore P: 0.5342\n",
      "Episode: 378 Total reward: 10.0 Training loss: 47.2421 Explore P: 0.5337\n",
      "Episode: 379 Total reward: 12.0 Training loss: 40.6806 Explore P: 0.5331\n",
      "Episode: 380 Total reward: 18.0 Training loss: 26.9115 Explore P: 0.5321\n",
      "Episode: 381 Total reward: 10.0 Training loss: 26.3018 Explore P: 0.5316\n",
      "Episode: 382 Total reward: 19.0 Training loss: 14.3693 Explore P: 0.5306\n",
      "Episode: 383 Total reward: 15.0 Training loss: 26.0188 Explore P: 0.5298\n",
      "Episode: 384 Total reward: 10.0 Training loss: 25.0125 Explore P: 0.5293\n",
      "Episode: 385 Total reward: 11.0 Training loss: 21.1318 Explore P: 0.5287\n",
      "Episode: 386 Total reward: 16.0 Training loss: 10.4116 Explore P: 0.5279\n",
      "Episode: 387 Total reward: 16.0 Training loss: 0.6766 Explore P: 0.5271\n",
      "Episode: 388 Total reward: 14.0 Training loss: 21.5795 Explore P: 0.5264\n",
      "Episode: 389 Total reward: 15.0 Training loss: 35.1157 Explore P: 0.5256\n",
      "Episode: 390 Total reward: 13.0 Training loss: 13.6170 Explore P: 0.5249\n",
      "Episode: 391 Total reward: 17.0 Training loss: 0.9952 Explore P: 0.5240\n",
      "Episode: 392 Total reward: 19.0 Training loss: 1.1524 Explore P: 0.5231\n",
      "Episode: 393 Total reward: 17.0 Training loss: 46.1327 Explore P: 0.5222\n",
      "Episode: 394 Total reward: 15.0 Training loss: 11.1858 Explore P: 0.5214\n",
      "Episode: 395 Total reward: 17.0 Training loss: 24.4490 Explore P: 0.5206\n",
      "Episode: 396 Total reward: 18.0 Training loss: 30.8845 Explore P: 0.5196\n",
      "Episode: 397 Total reward: 18.0 Training loss: 1.4104 Explore P: 0.5187\n",
      "Episode: 398 Total reward: 26.0 Training loss: 9.6371 Explore P: 0.5174\n",
      "Episode: 399 Total reward: 29.0 Training loss: 8.4831 Explore P: 0.5159\n",
      "Episode: 400 Total reward: 17.0 Training loss: 0.9758 Explore P: 0.5151\n",
      "Episode: 401 Total reward: 18.0 Training loss: 21.1125 Explore P: 0.5142\n",
      "Episode: 402 Total reward: 16.0 Training loss: 52.5240 Explore P: 0.5134\n",
      "Episode: 403 Total reward: 21.0 Training loss: 19.9804 Explore P: 0.5123\n",
      "Episode: 404 Total reward: 46.0 Training loss: 1.0526 Explore P: 0.5100\n",
      "Episode: 405 Total reward: 29.0 Training loss: 8.8313 Explore P: 0.5086\n",
      "Episode: 406 Total reward: 16.0 Training loss: 8.6349 Explore P: 0.5078\n",
      "Episode: 407 Total reward: 19.0 Training loss: 31.5029 Explore P: 0.5068\n",
      "Episode: 408 Total reward: 19.0 Training loss: 1.1777 Explore P: 0.5059\n",
      "Episode: 409 Total reward: 19.0 Training loss: 23.0780 Explore P: 0.5049\n",
      "Episode: 410 Total reward: 16.0 Training loss: 9.4722 Explore P: 0.5041\n",
      "Episode: 411 Total reward: 14.0 Training loss: 1.3035 Explore P: 0.5034\n",
      "Episode: 412 Total reward: 32.0 Training loss: 50.3717 Explore P: 0.5019\n",
      "Episode: 413 Total reward: 24.0 Training loss: 8.0549 Explore P: 0.5007\n",
      "Episode: 414 Total reward: 28.0 Training loss: 30.4451 Explore P: 0.4993\n",
      "Episode: 415 Total reward: 19.0 Training loss: 1.0113 Explore P: 0.4984\n",
      "Episode: 416 Total reward: 19.0 Training loss: 49.4136 Explore P: 0.4975\n",
      "Episode: 417 Total reward: 22.0 Training loss: 1.2230 Explore P: 0.4964\n",
      "Episode: 418 Total reward: 52.0 Training loss: 1.2204 Explore P: 0.4939\n",
      "Episode: 419 Total reward: 64.0 Training loss: 33.0258 Explore P: 0.4908\n",
      "Episode: 420 Total reward: 90.0 Training loss: 32.8577 Explore P: 0.4865\n",
      "Episode: 421 Total reward: 82.0 Training loss: 35.9520 Explore P: 0.4826\n",
      "Episode: 422 Total reward: 38.0 Training loss: 1.9858 Explore P: 0.4808\n",
      "Episode: 423 Total reward: 40.0 Training loss: 0.8769 Explore P: 0.4789\n",
      "Episode: 424 Total reward: 41.0 Training loss: 27.4960 Explore P: 0.4770\n",
      "Episode: 425 Total reward: 13.0 Training loss: 24.0802 Explore P: 0.4764\n",
      "Episode: 426 Total reward: 77.0 Training loss: 19.8195 Explore P: 0.4728\n",
      "Episode: 427 Total reward: 89.0 Training loss: 10.2825 Explore P: 0.4687\n",
      "Episode: 428 Total reward: 19.0 Training loss: 1.1981 Explore P: 0.4678\n",
      "Episode: 429 Total reward: 138.0 Training loss: 32.8315 Explore P: 0.4616\n",
      "Episode: 430 Total reward: 58.0 Training loss: 27.9853 Explore P: 0.4589\n",
      "Episode: 431 Total reward: 35.0 Training loss: 14.0388 Explore P: 0.4574\n",
      "Episode: 432 Total reward: 41.0 Training loss: 1.1469 Explore P: 0.4555\n",
      "Episode: 433 Total reward: 30.0 Training loss: 44.1706 Explore P: 0.4542\n",
      "Episode: 434 Total reward: 56.0 Training loss: 1.2538 Explore P: 0.4517\n",
      "Episode: 435 Total reward: 11.0 Training loss: 21.8018 Explore P: 0.4512\n",
      "Episode: 436 Total reward: 85.0 Training loss: 11.5478 Explore P: 0.4475\n",
      "Episode: 437 Total reward: 94.0 Training loss: 1.3027 Explore P: 0.4434\n",
      "Episode: 438 Total reward: 149.0 Training loss: 1.1437 Explore P: 0.4370\n",
      "Episode: 439 Total reward: 55.0 Training loss: 40.8034 Explore P: 0.4347\n",
      "Episode: 440 Total reward: 42.0 Training loss: 1.1480 Explore P: 0.4329\n",
      "Episode: 441 Total reward: 75.0 Training loss: 14.5949 Explore P: 0.4297\n",
      "Episode: 442 Total reward: 58.0 Training loss: 14.9048 Explore P: 0.4273\n",
      "Episode: 443 Total reward: 56.0 Training loss: 1.1651 Explore P: 0.4250\n",
      "Episode: 444 Total reward: 33.0 Training loss: 22.8100 Explore P: 0.4236\n",
      "Episode: 445 Total reward: 86.0 Training loss: 30.4447 Explore P: 0.4201\n",
      "Episode: 446 Total reward: 75.0 Training loss: 1.8539 Explore P: 0.4170\n",
      "Episode: 447 Total reward: 26.0 Training loss: 42.7157 Explore P: 0.4159\n",
      "Episode: 448 Total reward: 31.0 Training loss: 18.4740 Explore P: 0.4147\n",
      "Episode: 449 Total reward: 47.0 Training loss: 11.9448 Explore P: 0.4128\n",
      "Episode: 450 Total reward: 69.0 Training loss: 20.3454 Explore P: 0.4100\n",
      "Episode: 451 Total reward: 91.0 Training loss: 1.3511 Explore P: 0.4064\n",
      "Episode: 452 Total reward: 69.0 Training loss: 19.1706 Explore P: 0.4037\n",
      "Episode: 453 Total reward: 37.0 Training loss: 13.5659 Explore P: 0.4022\n",
      "Episode: 454 Total reward: 118.0 Training loss: 28.0634 Explore P: 0.3976\n",
      "Episode: 455 Total reward: 50.0 Training loss: 22.0595 Explore P: 0.3957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 456 Total reward: 33.0 Training loss: 22.6622 Explore P: 0.3944\n",
      "Episode: 457 Total reward: 35.0 Training loss: 21.2844 Explore P: 0.3931\n",
      "Episode: 458 Total reward: 100.0 Training loss: 0.8245 Explore P: 0.3893\n",
      "Episode: 459 Total reward: 24.0 Training loss: 9.9272 Explore P: 0.3883\n",
      "Episode: 460 Total reward: 52.0 Training loss: 12.6375 Explore P: 0.3864\n",
      "Episode: 461 Total reward: 26.0 Training loss: 26.1121 Explore P: 0.3854\n",
      "Episode: 462 Total reward: 35.0 Training loss: 14.6824 Explore P: 0.3841\n",
      "Episode: 463 Total reward: 31.0 Training loss: 26.2202 Explore P: 0.3829\n",
      "Episode: 464 Total reward: 23.0 Training loss: 68.1734 Explore P: 0.3821\n",
      "Episode: 465 Total reward: 33.0 Training loss: 1.4607 Explore P: 0.3809\n",
      "Episode: 466 Total reward: 46.0 Training loss: 1.1091 Explore P: 0.3792\n",
      "Episode: 467 Total reward: 29.0 Training loss: 2.1241 Explore P: 0.3781\n",
      "Episode: 468 Total reward: 27.0 Training loss: 49.7501 Explore P: 0.3771\n",
      "Episode: 469 Total reward: 43.0 Training loss: 1.4849 Explore P: 0.3755\n",
      "Episode: 470 Total reward: 88.0 Training loss: 57.6174 Explore P: 0.3723\n",
      "Episode: 471 Total reward: 105.0 Training loss: 12.2342 Explore P: 0.3685\n",
      "Episode: 472 Total reward: 130.0 Training loss: 1.6827 Explore P: 0.3639\n",
      "Episode: 473 Total reward: 43.0 Training loss: 46.9853 Explore P: 0.3624\n",
      "Episode: 474 Total reward: 95.0 Training loss: 16.2040 Explore P: 0.3590\n",
      "Episode: 475 Total reward: 74.0 Training loss: 9.4023 Explore P: 0.3565\n",
      "Episode: 476 Total reward: 46.0 Training loss: 1.5551 Explore P: 0.3549\n",
      "Episode: 477 Total reward: 26.0 Training loss: 0.8204 Explore P: 0.3540\n",
      "Episode: 478 Total reward: 43.0 Training loss: 1.3682 Explore P: 0.3525\n",
      "Episode: 479 Total reward: 73.0 Training loss: 26.5672 Explore P: 0.3500\n",
      "Episode: 480 Total reward: 81.0 Training loss: 14.1448 Explore P: 0.3473\n",
      "Episode: 481 Total reward: 44.0 Training loss: 2.9196 Explore P: 0.3458\n",
      "Episode: 482 Total reward: 65.0 Training loss: 1.3212 Explore P: 0.3436\n",
      "Episode: 483 Total reward: 37.0 Training loss: 39.6581 Explore P: 0.3424\n",
      "Episode: 484 Total reward: 64.0 Training loss: 26.3630 Explore P: 0.3403\n",
      "Episode: 485 Total reward: 177.0 Training loss: 15.4282 Explore P: 0.3345\n",
      "Episode: 486 Total reward: 43.0 Training loss: 81.1011 Explore P: 0.3331\n",
      "Episode: 487 Total reward: 57.0 Training loss: 49.8459 Explore P: 0.3312\n",
      "Episode: 488 Total reward: 34.0 Training loss: 50.2430 Explore P: 0.3302\n",
      "Episode: 489 Total reward: 61.0 Training loss: 10.6844 Explore P: 0.3282\n",
      "Episode: 490 Total reward: 52.0 Training loss: 1.3888 Explore P: 0.3266\n",
      "Episode: 491 Total reward: 101.0 Training loss: 1.9802 Explore P: 0.3234\n",
      "Episode: 492 Total reward: 93.0 Training loss: 20.0803 Explore P: 0.3205\n",
      "Episode: 493 Total reward: 59.0 Training loss: 2.5854 Explore P: 0.3186\n",
      "Episode: 494 Total reward: 28.0 Training loss: 89.5687 Explore P: 0.3178\n",
      "Episode: 495 Total reward: 56.0 Training loss: 1.2630 Explore P: 0.3161\n",
      "Episode: 496 Total reward: 67.0 Training loss: 59.0761 Explore P: 0.3140\n",
      "Episode: 497 Total reward: 57.0 Training loss: 66.9624 Explore P: 0.3123\n",
      "Episode: 498 Total reward: 67.0 Training loss: 2.2245 Explore P: 0.3103\n",
      "Episode: 499 Total reward: 48.0 Training loss: 60.0631 Explore P: 0.3088\n",
      "Episode: 500 Total reward: 48.0 Training loss: 1.5806 Explore P: 0.3074\n",
      "Episode: 501 Total reward: 100.0 Training loss: 1.8303 Explore P: 0.3044\n",
      "Episode: 502 Total reward: 103.0 Training loss: 1.5197 Explore P: 0.3014\n",
      "Episode: 503 Total reward: 74.0 Training loss: 68.7228 Explore P: 0.2993\n",
      "Episode: 504 Total reward: 56.0 Training loss: 90.1230 Explore P: 0.2977\n",
      "Episode: 505 Total reward: 60.0 Training loss: 1.5862 Explore P: 0.2959\n",
      "Episode: 506 Total reward: 43.0 Training loss: 1.7121 Explore P: 0.2947\n",
      "Episode: 507 Total reward: 50.0 Training loss: 178.0629 Explore P: 0.2933\n",
      "Episode: 508 Total reward: 52.0 Training loss: 63.9608 Explore P: 0.2918\n",
      "Episode: 509 Total reward: 97.0 Training loss: 1.5226 Explore P: 0.2891\n",
      "Episode: 510 Total reward: 61.0 Training loss: 68.7424 Explore P: 0.2874\n",
      "Episode: 511 Total reward: 57.0 Training loss: 1.2296 Explore P: 0.2858\n",
      "Episode: 512 Total reward: 57.0 Training loss: 10.0570 Explore P: 0.2843\n",
      "Episode: 513 Total reward: 48.0 Training loss: 39.6687 Explore P: 0.2830\n",
      "Episode: 514 Total reward: 55.0 Training loss: 1.3050 Explore P: 0.2815\n",
      "Episode: 515 Total reward: 60.0 Training loss: 120.5658 Explore P: 0.2798\n",
      "Episode: 516 Total reward: 61.0 Training loss: 11.4563 Explore P: 0.2782\n",
      "Episode: 517 Total reward: 73.0 Training loss: 3.1265 Explore P: 0.2762\n",
      "Episode: 518 Total reward: 120.0 Training loss: 2.2454 Explore P: 0.2731\n",
      "Episode: 519 Total reward: 64.0 Training loss: 1.4212 Explore P: 0.2714\n",
      "Episode: 520 Total reward: 105.0 Training loss: 1.7973 Explore P: 0.2687\n",
      "Episode: 521 Total reward: 109.0 Training loss: 39.8293 Explore P: 0.2659\n",
      "Episode: 522 Total reward: 64.0 Training loss: 1.4553 Explore P: 0.2642\n",
      "Episode: 523 Total reward: 163.0 Training loss: 78.5532 Explore P: 0.2601\n",
      "Episode: 524 Total reward: 66.0 Training loss: 2.4455 Explore P: 0.2585\n",
      "Episode: 525 Total reward: 38.0 Training loss: 2.2530 Explore P: 0.2575\n",
      "Episode: 526 Total reward: 45.0 Training loss: 2.1424 Explore P: 0.2564\n",
      "Episode: 527 Total reward: 55.0 Training loss: 1.1560 Explore P: 0.2551\n",
      "Episode: 528 Total reward: 37.0 Training loss: 44.2105 Explore P: 0.2542\n",
      "Episode: 529 Total reward: 52.0 Training loss: 1.2577 Explore P: 0.2529\n",
      "Episode: 530 Total reward: 68.0 Training loss: 2.7484 Explore P: 0.2512\n",
      "Episode: 531 Total reward: 41.0 Training loss: 53.0788 Explore P: 0.2503\n",
      "Episode: 532 Total reward: 52.0 Training loss: 1.7812 Explore P: 0.2490\n",
      "Episode: 533 Total reward: 41.0 Training loss: 103.5223 Explore P: 0.2480\n",
      "Episode: 534 Total reward: 32.0 Training loss: 2.1998 Explore P: 0.2473\n",
      "Episode: 535 Total reward: 44.0 Training loss: 88.5896 Explore P: 0.2462\n",
      "Episode: 536 Total reward: 67.0 Training loss: 1.5747 Explore P: 0.2447\n",
      "Episode: 537 Total reward: 69.0 Training loss: 130.0918 Explore P: 0.2430\n",
      "Episode: 538 Total reward: 50.0 Training loss: 1.9182 Explore P: 0.2419\n",
      "Episode: 539 Total reward: 55.0 Training loss: 1.0937 Explore P: 0.2406\n",
      "Episode: 540 Total reward: 39.0 Training loss: 60.1235 Explore P: 0.2397\n",
      "Episode: 541 Total reward: 41.0 Training loss: 1.2063 Explore P: 0.2388\n",
      "Episode: 542 Total reward: 16.0 Training loss: 1.0643 Explore P: 0.2384\n",
      "Episode: 543 Total reward: 35.0 Training loss: 1.9651 Explore P: 0.2376\n",
      "Episode: 544 Total reward: 52.0 Training loss: 59.1756 Explore P: 0.2364\n",
      "Episode: 545 Total reward: 78.0 Training loss: 20.7772 Explore P: 0.2347\n",
      "Episode: 546 Total reward: 32.0 Training loss: 1.4485 Explore P: 0.2339\n",
      "Episode: 547 Total reward: 51.0 Training loss: 51.3965 Explore P: 0.2328\n",
      "Episode: 548 Total reward: 73.0 Training loss: 1.4272 Explore P: 0.2312\n",
      "Episode: 549 Total reward: 32.0 Training loss: 1.4522 Explore P: 0.2305\n",
      "Episode: 550 Total reward: 29.0 Training loss: 88.4986 Explore P: 0.2298\n",
      "Episode: 551 Total reward: 26.0 Training loss: 41.7647 Explore P: 0.2293\n",
      "Episode: 552 Total reward: 29.0 Training loss: 20.8772 Explore P: 0.2286\n",
      "Episode: 553 Total reward: 27.0 Training loss: 3.0069 Explore P: 0.2280\n",
      "Episode: 554 Total reward: 35.0 Training loss: 87.2098 Explore P: 0.2273\n",
      "Episode: 555 Total reward: 53.0 Training loss: 18.7500 Explore P: 0.2261\n",
      "Episode: 556 Total reward: 39.0 Training loss: 110.2133 Explore P: 0.2253\n",
      "Episode: 557 Total reward: 30.0 Training loss: 3.0223 Explore P: 0.2246\n",
      "Episode: 558 Total reward: 27.0 Training loss: 80.9183 Explore P: 0.2241\n",
      "Episode: 559 Total reward: 19.0 Training loss: 2.6978 Explore P: 0.2237\n",
      "Episode: 560 Total reward: 36.0 Training loss: 29.6172 Explore P: 0.2229\n",
      "Episode: 561 Total reward: 32.0 Training loss: 1.8184 Explore P: 0.2222\n",
      "Episode: 562 Total reward: 29.0 Training loss: 1.7329 Explore P: 0.2216\n",
      "Episode: 563 Total reward: 33.0 Training loss: 2.3021 Explore P: 0.2209\n",
      "Episode: 564 Total reward: 34.0 Training loss: 241.0751 Explore P: 0.2202\n",
      "Episode: 565 Total reward: 25.0 Training loss: 1.6825 Explore P: 0.2197\n",
      "Episode: 566 Total reward: 34.0 Training loss: 1.7591 Explore P: 0.2190\n",
      "Episode: 567 Total reward: 24.0 Training loss: 1.8843 Explore P: 0.2185\n",
      "Episode: 568 Total reward: 24.0 Training loss: 1.7971 Explore P: 0.2180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 569 Total reward: 33.0 Training loss: 1.1573 Explore P: 0.2173\n",
      "Episode: 570 Total reward: 33.0 Training loss: 81.0160 Explore P: 0.2166\n",
      "Episode: 571 Total reward: 31.0 Training loss: 1.4519 Explore P: 0.2159\n",
      "Episode: 572 Total reward: 41.0 Training loss: 111.7910 Explore P: 0.2151\n",
      "Episode: 573 Total reward: 65.0 Training loss: 99.5643 Explore P: 0.2138\n",
      "Episode: 574 Total reward: 75.0 Training loss: 2.3873 Explore P: 0.2123\n",
      "Episode: 575 Total reward: 22.0 Training loss: 2.3372 Explore P: 0.2118\n",
      "Episode: 576 Total reward: 40.0 Training loss: 1.7618 Explore P: 0.2110\n",
      "Episode: 577 Total reward: 29.0 Training loss: 80.7187 Explore P: 0.2104\n",
      "Episode: 578 Total reward: 33.0 Training loss: 108.6433 Explore P: 0.2098\n",
      "Episode: 579 Total reward: 24.0 Training loss: 82.4971 Explore P: 0.2093\n",
      "Episode: 580 Total reward: 28.0 Training loss: 2.7331 Explore P: 0.2087\n",
      "Episode: 581 Total reward: 22.0 Training loss: 1.5953 Explore P: 0.2083\n",
      "Episode: 582 Total reward: 26.0 Training loss: 103.5604 Explore P: 0.2078\n",
      "Episode: 583 Total reward: 18.0 Training loss: 1.8136 Explore P: 0.2074\n",
      "Episode: 584 Total reward: 22.0 Training loss: 2.3188 Explore P: 0.2070\n",
      "Episode: 585 Total reward: 32.0 Training loss: 172.5578 Explore P: 0.2064\n",
      "Episode: 586 Total reward: 33.0 Training loss: 1.9053 Explore P: 0.2057\n",
      "Episode: 587 Total reward: 27.0 Training loss: 1.6949 Explore P: 0.2052\n",
      "Episode: 588 Total reward: 64.0 Training loss: 2.1253 Explore P: 0.2039\n",
      "Episode: 589 Total reward: 34.0 Training loss: 1.6054 Explore P: 0.2033\n",
      "Episode: 590 Total reward: 28.0 Training loss: 2.1213 Explore P: 0.2027\n",
      "Episode: 591 Total reward: 56.0 Training loss: 1.0573 Explore P: 0.2017\n",
      "Episode: 592 Total reward: 52.0 Training loss: 0.8298 Explore P: 0.2007\n",
      "Episode: 593 Total reward: 64.0 Training loss: 1.0135 Explore P: 0.1994\n",
      "Episode: 594 Total reward: 44.0 Training loss: 1.2685 Explore P: 0.1986\n",
      "Episode: 595 Total reward: 74.0 Training loss: 1.2833 Explore P: 0.1972\n",
      "Episode: 596 Total reward: 89.0 Training loss: 64.5922 Explore P: 0.1956\n",
      "Episode: 597 Total reward: 71.0 Training loss: 1.9868 Explore P: 0.1943\n",
      "Episode: 598 Total reward: 49.0 Training loss: 0.9405 Explore P: 0.1934\n",
      "Episode: 599 Total reward: 51.0 Training loss: 1.0458 Explore P: 0.1924\n",
      "Episode: 600 Total reward: 62.0 Training loss: 1.5689 Explore P: 0.1913\n",
      "Episode: 601 Total reward: 154.0 Training loss: 1.3857 Explore P: 0.1885\n",
      "Episode: 602 Total reward: 77.0 Training loss: 1.0084 Explore P: 0.1872\n",
      "Episode: 603 Total reward: 120.0 Training loss: 1.2823 Explore P: 0.1850\n",
      "Episode: 604 Total reward: 187.0 Training loss: 84.6307 Explore P: 0.1818\n",
      "Episode: 605 Total reward: 127.0 Training loss: 65.1480 Explore P: 0.1796\n",
      "Episode: 606 Total reward: 86.0 Training loss: 1.0120 Explore P: 0.1782\n",
      "Episode: 607 Total reward: 89.0 Training loss: 1.6015 Explore P: 0.1767\n",
      "Episode: 608 Total reward: 165.0 Training loss: 0.7821 Explore P: 0.1740\n",
      "Episode: 609 Total reward: 134.0 Training loss: 1.3966 Explore P: 0.1718\n",
      "Episode: 610 Total reward: 69.0 Training loss: 1.8404 Explore P: 0.1707\n",
      "Episode: 611 Total reward: 131.0 Training loss: 1.0045 Explore P: 0.1686\n",
      "Episode: 612 Total reward: 107.0 Training loss: 0.5879 Explore P: 0.1669\n",
      "Episode: 614 Total reward: 74.0 Training loss: 98.8429 Explore P: 0.1626\n",
      "Episode: 616 Total reward: 25.0 Training loss: 105.2034 Explore P: 0.1592\n",
      "Episode: 617 Total reward: 159.0 Training loss: 2.0225 Explore P: 0.1569\n",
      "Episode: 618 Total reward: 87.0 Training loss: 1.2234 Explore P: 0.1556\n",
      "Episode: 619 Total reward: 184.0 Training loss: 1.2151 Explore P: 0.1530\n",
      "Episode: 620 Total reward: 152.0 Training loss: 65.4018 Explore P: 0.1508\n",
      "Episode: 621 Total reward: 59.0 Training loss: 108.6585 Explore P: 0.1500\n",
      "Episode: 622 Total reward: 124.0 Training loss: 0.6766 Explore P: 0.1483\n",
      "Episode: 624 Total reward: 169.0 Training loss: 1.4488 Explore P: 0.1432\n",
      "Episode: 625 Total reward: 93.0 Training loss: 1.1581 Explore P: 0.1420\n",
      "Episode: 628 Total reward: 68.0 Training loss: 1.3268 Explore P: 0.1360\n",
      "Episode: 629 Total reward: 96.0 Training loss: 1.1833 Explore P: 0.1348\n",
      "Episode: 630 Total reward: 158.0 Training loss: 62.4533 Explore P: 0.1328\n",
      "Episode: 632 Total reward: 37.0 Training loss: 1.2712 Explore P: 0.1299\n",
      "Episode: 633 Total reward: 101.0 Training loss: 166.9169 Explore P: 0.1287\n",
      "Episode: 634 Total reward: 107.0 Training loss: 0.9701 Explore P: 0.1275\n",
      "Episode: 635 Total reward: 122.0 Training loss: 1.2777 Explore P: 0.1260\n",
      "Episode: 636 Total reward: 79.0 Training loss: 1.4546 Explore P: 0.1251\n",
      "Episode: 637 Total reward: 152.0 Training loss: 1.1918 Explore P: 0.1234\n",
      "Episode: 638 Total reward: 74.0 Training loss: 1.1390 Explore P: 0.1226\n",
      "Episode: 639 Total reward: 65.0 Training loss: 161.2593 Explore P: 0.1218\n",
      "Episode: 640 Total reward: 54.0 Training loss: 1.1560 Explore P: 0.1212\n",
      "Episode: 641 Total reward: 87.0 Training loss: 1.4721 Explore P: 0.1203\n",
      "Episode: 642 Total reward: 57.0 Training loss: 252.3668 Explore P: 0.1196\n",
      "Episode: 643 Total reward: 53.0 Training loss: 1.8368 Explore P: 0.1191\n",
      "Episode: 644 Total reward: 41.0 Training loss: 1.7627 Explore P: 0.1186\n",
      "Episode: 645 Total reward: 40.0 Training loss: 1.7677 Explore P: 0.1182\n",
      "Episode: 646 Total reward: 53.0 Training loss: 1.2815 Explore P: 0.1176\n",
      "Episode: 647 Total reward: 42.0 Training loss: 1.1280 Explore P: 0.1172\n",
      "Episode: 648 Total reward: 46.0 Training loss: 1.5583 Explore P: 0.1167\n",
      "Episode: 649 Total reward: 52.0 Training loss: 1.3432 Explore P: 0.1161\n",
      "Episode: 650 Total reward: 79.0 Training loss: 89.2163 Explore P: 0.1153\n",
      "Episode: 651 Total reward: 62.0 Training loss: 1.3327 Explore P: 0.1146\n",
      "Episode: 652 Total reward: 52.0 Training loss: 1.7175 Explore P: 0.1141\n",
      "Episode: 653 Total reward: 28.0 Training loss: 83.1608 Explore P: 0.1138\n",
      "Episode: 654 Total reward: 40.0 Training loss: 2.3537 Explore P: 0.1134\n",
      "Episode: 655 Total reward: 39.0 Training loss: 1.0800 Explore P: 0.1130\n",
      "Episode: 656 Total reward: 68.0 Training loss: 0.4998 Explore P: 0.1123\n",
      "Episode: 657 Total reward: 40.0 Training loss: 1.1999 Explore P: 0.1119\n",
      "Episode: 658 Total reward: 51.0 Training loss: 1.6626 Explore P: 0.1114\n",
      "Episode: 659 Total reward: 31.0 Training loss: 154.3246 Explore P: 0.1110\n",
      "Episode: 660 Total reward: 40.0 Training loss: 1.9711 Explore P: 0.1106\n",
      "Episode: 661 Total reward: 51.0 Training loss: 2.1602 Explore P: 0.1101\n",
      "Episode: 662 Total reward: 47.0 Training loss: 1.4136 Explore P: 0.1097\n",
      "Episode: 663 Total reward: 27.0 Training loss: 2.0998 Explore P: 0.1094\n",
      "Episode: 664 Total reward: 32.0 Training loss: 1.7485 Explore P: 0.1091\n",
      "Episode: 665 Total reward: 38.0 Training loss: 1.5456 Explore P: 0.1087\n",
      "Episode: 666 Total reward: 27.0 Training loss: 2.0018 Explore P: 0.1084\n",
      "Episode: 667 Total reward: 35.0 Training loss: 1.4067 Explore P: 0.1081\n",
      "Episode: 668 Total reward: 40.0 Training loss: 2.1918 Explore P: 0.1077\n",
      "Episode: 669 Total reward: 40.0 Training loss: 2.0406 Explore P: 0.1073\n",
      "Episode: 670 Total reward: 48.0 Training loss: 1.2496 Explore P: 0.1068\n",
      "Episode: 671 Total reward: 39.0 Training loss: 1.3459 Explore P: 0.1065\n",
      "Episode: 672 Total reward: 42.0 Training loss: 2.1590 Explore P: 0.1061\n",
      "Episode: 673 Total reward: 27.0 Training loss: 156.1920 Explore P: 0.1058\n",
      "Episode: 674 Total reward: 39.0 Training loss: 2.1776 Explore P: 0.1054\n",
      "Episode: 675 Total reward: 32.0 Training loss: 1.2838 Explore P: 0.1051\n",
      "Episode: 676 Total reward: 34.0 Training loss: 163.6666 Explore P: 0.1048\n",
      "Episode: 677 Total reward: 25.0 Training loss: 82.3794 Explore P: 0.1046\n",
      "Episode: 678 Total reward: 30.0 Training loss: 1.7189 Explore P: 0.1043\n",
      "Episode: 679 Total reward: 22.0 Training loss: 1.9707 Explore P: 0.1041\n",
      "Episode: 680 Total reward: 53.0 Training loss: 1.5273 Explore P: 0.1036\n",
      "Episode: 681 Total reward: 40.0 Training loss: 1.1515 Explore P: 0.1032\n",
      "Episode: 682 Total reward: 39.0 Training loss: 166.4419 Explore P: 0.1028\n",
      "Episode: 683 Total reward: 40.0 Training loss: 1.1850 Explore P: 0.1025\n",
      "Episode: 684 Total reward: 37.0 Training loss: 1.3132 Explore P: 0.1021\n",
      "Episode: 685 Total reward: 45.0 Training loss: 1.8807 Explore P: 0.1017\n",
      "Episode: 686 Total reward: 33.0 Training loss: 162.2689 Explore P: 0.1014\n",
      "Episode: 687 Total reward: 43.0 Training loss: 1.5290 Explore P: 0.1010\n",
      "Episode: 688 Total reward: 34.0 Training loss: 2.0542 Explore P: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 689 Total reward: 33.0 Training loss: 0.8720 Explore P: 0.1004\n",
      "Episode: 690 Total reward: 38.0 Training loss: 137.7136 Explore P: 0.1001\n",
      "Episode: 691 Total reward: 28.0 Training loss: 0.8304 Explore P: 0.0998\n",
      "Episode: 692 Total reward: 46.0 Training loss: 1.0258 Explore P: 0.0994\n",
      "Episode: 693 Total reward: 40.0 Training loss: 2.2671 Explore P: 0.0990\n",
      "Episode: 694 Total reward: 36.0 Training loss: 2.3930 Explore P: 0.0987\n",
      "Episode: 695 Total reward: 31.0 Training loss: 1.4558 Explore P: 0.0984\n",
      "Episode: 696 Total reward: 37.0 Training loss: 1.7293 Explore P: 0.0981\n",
      "Episode: 697 Total reward: 30.0 Training loss: 1.4959 Explore P: 0.0979\n",
      "Episode: 698 Total reward: 50.0 Training loss: 0.8838 Explore P: 0.0974\n",
      "Episode: 699 Total reward: 38.0 Training loss: 157.8241 Explore P: 0.0971\n",
      "Episode: 700 Total reward: 114.0 Training loss: 159.2189 Explore P: 0.0961\n",
      "Episode: 701 Total reward: 54.0 Training loss: 1.4330 Explore P: 0.0956\n",
      "Episode: 702 Total reward: 54.0 Training loss: 76.3483 Explore P: 0.0952\n",
      "Episode: 703 Total reward: 44.0 Training loss: 1.2383 Explore P: 0.0948\n",
      "Episode: 704 Total reward: 57.0 Training loss: 1.6718 Explore P: 0.0943\n",
      "Episode: 705 Total reward: 44.0 Training loss: 0.9592 Explore P: 0.0939\n",
      "Episode: 706 Total reward: 37.0 Training loss: 104.3800 Explore P: 0.0936\n",
      "Episode: 707 Total reward: 39.0 Training loss: 213.2441 Explore P: 0.0933\n",
      "Episode: 708 Total reward: 29.0 Training loss: 1.4483 Explore P: 0.0931\n",
      "Episode: 709 Total reward: 52.0 Training loss: 1.8870 Explore P: 0.0926\n",
      "Episode: 710 Total reward: 46.0 Training loss: 44.9901 Explore P: 0.0923\n",
      "Episode: 711 Total reward: 72.0 Training loss: 1.7377 Explore P: 0.0917\n",
      "Episode: 712 Total reward: 63.0 Training loss: 0.8666 Explore P: 0.0912\n",
      "Episode: 713 Total reward: 53.0 Training loss: 79.0366 Explore P: 0.0907\n",
      "Episode: 714 Total reward: 48.0 Training loss: 1.5239 Explore P: 0.0903\n",
      "Episode: 715 Total reward: 56.0 Training loss: 1.4794 Explore P: 0.0899\n",
      "Episode: 716 Total reward: 75.0 Training loss: 0.8950 Explore P: 0.0893\n",
      "Episode: 717 Total reward: 82.0 Training loss: 0.9480 Explore P: 0.0886\n",
      "Episode: 718 Total reward: 63.0 Training loss: 173.5232 Explore P: 0.0882\n",
      "Episode: 719 Total reward: 34.0 Training loss: 1.5958 Explore P: 0.0879\n",
      "Episode: 720 Total reward: 65.0 Training loss: 147.1462 Explore P: 0.0874\n",
      "Episode: 721 Total reward: 73.0 Training loss: 1.6412 Explore P: 0.0868\n",
      "Episode: 722 Total reward: 48.0 Training loss: 1.6638 Explore P: 0.0865\n",
      "Episode: 723 Total reward: 107.0 Training loss: 0.8579 Explore P: 0.0856\n",
      "Episode: 724 Total reward: 61.0 Training loss: 0.9523 Explore P: 0.0852\n",
      "Episode: 725 Total reward: 50.0 Training loss: 0.9442 Explore P: 0.0848\n",
      "Episode: 726 Total reward: 55.0 Training loss: 154.9500 Explore P: 0.0844\n",
      "Episode: 727 Total reward: 45.0 Training loss: 0.8681 Explore P: 0.0841\n",
      "Episode: 728 Total reward: 68.0 Training loss: 1.0091 Explore P: 0.0836\n",
      "Episode: 729 Total reward: 47.0 Training loss: 1.5492 Explore P: 0.0832\n",
      "Episode: 730 Total reward: 47.0 Training loss: 1.3286 Explore P: 0.0829\n",
      "Episode: 731 Total reward: 54.0 Training loss: 0.7156 Explore P: 0.0825\n",
      "Episode: 732 Total reward: 113.0 Training loss: 1.4777 Explore P: 0.0817\n",
      "Episode: 733 Total reward: 49.0 Training loss: 60.4213 Explore P: 0.0813\n",
      "Episode: 734 Total reward: 47.0 Training loss: 0.5768 Explore P: 0.0810\n",
      "Episode: 735 Total reward: 101.0 Training loss: 32.8518 Explore P: 0.0803\n",
      "Episode: 736 Total reward: 84.0 Training loss: 0.6500 Explore P: 0.0797\n",
      "Episode: 738 Total reward: 43.0 Training loss: 53.2252 Explore P: 0.0780\n",
      "Episode: 739 Total reward: 104.0 Training loss: 1.1083 Explore P: 0.0773\n",
      "Episode: 740 Total reward: 81.0 Training loss: 0.5602 Explore P: 0.0768\n",
      "Episode: 742 Total reward: 30.0 Training loss: 0.8807 Explore P: 0.0752\n",
      "Episode: 743 Total reward: 87.0 Training loss: 0.4555 Explore P: 0.0747\n",
      "Episode: 744 Total reward: 60.0 Training loss: 0.8970 Explore P: 0.0743\n",
      "Episode: 746 Total reward: 35.0 Training loss: 0.5986 Explore P: 0.0728\n",
      "Episode: 747 Total reward: 68.0 Training loss: 0.3693 Explore P: 0.0724\n",
      "Episode: 749 Total reward: 80.0 Training loss: 0.7259 Explore P: 0.0706\n",
      "Episode: 751 Total reward: 26.0 Training loss: 71.4295 Explore P: 0.0693\n",
      "Episode: 753 Total reward: 105.0 Training loss: 0.8363 Explore P: 0.0675\n",
      "Episode: 754 Total reward: 78.0 Training loss: 0.4629 Explore P: 0.0671\n",
      "Episode: 755 Total reward: 91.0 Training loss: 0.4682 Explore P: 0.0665\n",
      "Episode: 757 Total reward: 66.0 Training loss: 0.4542 Explore P: 0.0651\n",
      "Episode: 758 Total reward: 82.0 Training loss: 508.5158 Explore P: 0.0646\n",
      "Episode: 759 Total reward: 146.0 Training loss: 0.4230 Explore P: 0.0638\n",
      "Episode: 760 Total reward: 105.0 Training loss: 0.6298 Explore P: 0.0633\n",
      "Episode: 761 Total reward: 93.0 Training loss: 50.9300 Explore P: 0.0628\n",
      "Episode: 762 Total reward: 82.0 Training loss: 6.0748 Explore P: 0.0623\n",
      "Episode: 764 Total reward: 126.0 Training loss: 0.5732 Explore P: 0.0607\n",
      "Episode: 766 Total reward: 90.0 Training loss: 0.3495 Explore P: 0.0592\n",
      "Episode: 768 Total reward: 55.0 Training loss: 0.1689 Explore P: 0.0580\n",
      "Episode: 769 Total reward: 146.0 Training loss: 0.3617 Explore P: 0.0573\n",
      "Episode: 770 Total reward: 187.0 Training loss: 0.4983 Explore P: 0.0564\n",
      "Episode: 772 Total reward: 10.0 Training loss: 0.4511 Explore P: 0.0554\n",
      "Episode: 774 Total reward: 197.0 Training loss: 0.3625 Explore P: 0.0537\n",
      "Episode: 775 Total reward: 138.0 Training loss: 0.2953 Explore P: 0.0531\n",
      "Episode: 777 Total reward: 56.0 Training loss: 0.2001 Explore P: 0.0520\n",
      "Episode: 778 Total reward: 130.0 Training loss: 0.5933 Explore P: 0.0514\n",
      "Episode: 779 Total reward: 126.0 Training loss: 0.4155 Explore P: 0.0509\n",
      "Episode: 781 Total reward: 54.0 Training loss: 0.4614 Explore P: 0.0499\n",
      "Episode: 782 Total reward: 144.0 Training loss: 0.3769 Explore P: 0.0493\n",
      "Episode: 783 Total reward: 125.0 Training loss: 0.7088 Explore P: 0.0488\n",
      "Episode: 785 Total reward: 14.0 Training loss: 0.6739 Explore P: 0.0480\n",
      "Episode: 786 Total reward: 142.0 Training loss: 0.6036 Explore P: 0.0475\n",
      "Episode: 787 Total reward: 101.0 Training loss: 0.8036 Explore P: 0.0471\n",
      "Episode: 788 Total reward: 103.0 Training loss: 0.4220 Explore P: 0.0467\n",
      "Episode: 789 Total reward: 33.0 Training loss: 0.7764 Explore P: 0.0466\n",
      "Episode: 790 Total reward: 33.0 Training loss: 0.5447 Explore P: 0.0465\n",
      "Episode: 791 Total reward: 24.0 Training loss: 0.7480 Explore P: 0.0464\n",
      "Episode: 792 Total reward: 36.0 Training loss: 0.2715 Explore P: 0.0463\n",
      "Episode: 793 Total reward: 38.0 Training loss: 0.4637 Explore P: 0.0461\n",
      "Episode: 794 Total reward: 21.0 Training loss: 0.9202 Explore P: 0.0460\n",
      "Episode: 795 Total reward: 23.0 Training loss: 0.5464 Explore P: 0.0460\n",
      "Episode: 796 Total reward: 34.0 Training loss: 0.6491 Explore P: 0.0458\n",
      "Episode: 797 Total reward: 31.0 Training loss: 0.6272 Explore P: 0.0457\n",
      "Episode: 798 Total reward: 35.0 Training loss: 0.5719 Explore P: 0.0456\n",
      "Episode: 799 Total reward: 28.0 Training loss: 0.7403 Explore P: 0.0455\n",
      "Episode: 800 Total reward: 18.0 Training loss: 12.1581 Explore P: 0.0454\n",
      "Episode: 801 Total reward: 30.0 Training loss: 0.7395 Explore P: 0.0453\n",
      "Episode: 802 Total reward: 31.0 Training loss: 39.5641 Explore P: 0.0452\n",
      "Episode: 803 Total reward: 35.0 Training loss: 1.3258 Explore P: 0.0451\n",
      "Episode: 804 Total reward: 37.0 Training loss: 0.6722 Explore P: 0.0450\n",
      "Episode: 805 Total reward: 29.0 Training loss: 36.8772 Explore P: 0.0449\n",
      "Episode: 806 Total reward: 37.0 Training loss: 3.5897 Explore P: 0.0447\n",
      "Episode: 807 Total reward: 33.0 Training loss: 0.6752 Explore P: 0.0446\n",
      "Episode: 808 Total reward: 26.0 Training loss: 0.3682 Explore P: 0.0445\n",
      "Episode: 809 Total reward: 30.0 Training loss: 0.8445 Explore P: 0.0444\n",
      "Episode: 810 Total reward: 39.0 Training loss: 0.7335 Explore P: 0.0443\n",
      "Episode: 811 Total reward: 30.0 Training loss: 1.1964 Explore P: 0.0442\n",
      "Episode: 812 Total reward: 31.0 Training loss: 0.9571 Explore P: 0.0441\n",
      "Episode: 813 Total reward: 27.0 Training loss: 1.1685 Explore P: 0.0440\n",
      "Episode: 814 Total reward: 32.0 Training loss: 1.0654 Explore P: 0.0439\n",
      "Episode: 815 Total reward: 23.0 Training loss: 0.9554 Explore P: 0.0438\n",
      "Episode: 816 Total reward: 37.0 Training loss: 1.9959 Explore P: 0.0437\n",
      "Episode: 817 Total reward: 52.0 Training loss: 231.6594 Explore P: 0.0435\n",
      "Episode: 818 Total reward: 31.0 Training loss: 1.6173 Explore P: 0.0434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 819 Total reward: 52.0 Training loss: 0.4624 Explore P: 0.0432\n",
      "Episode: 820 Total reward: 77.0 Training loss: 0.7639 Explore P: 0.0430\n",
      "Episode: 821 Total reward: 39.0 Training loss: 0.7079 Explore P: 0.0429\n",
      "Episode: 822 Total reward: 39.0 Training loss: 390.8020 Explore P: 0.0427\n",
      "Episode: 823 Total reward: 67.0 Training loss: 0.4966 Explore P: 0.0425\n",
      "Episode: 824 Total reward: 46.0 Training loss: 0.5360 Explore P: 0.0424\n",
      "Episode: 825 Total reward: 89.0 Training loss: 213.4911 Explore P: 0.0421\n",
      "Episode: 826 Total reward: 38.0 Training loss: 0.4477 Explore P: 0.0420\n",
      "Episode: 827 Total reward: 35.0 Training loss: 1.0678 Explore P: 0.0418\n",
      "Episode: 828 Total reward: 63.0 Training loss: 0.7650 Explore P: 0.0416\n",
      "Episode: 829 Total reward: 77.0 Training loss: 0.8457 Explore P: 0.0414\n",
      "Episode: 830 Total reward: 66.0 Training loss: 0.8227 Explore P: 0.0412\n",
      "Episode: 831 Total reward: 34.0 Training loss: 1.3803 Explore P: 0.0411\n",
      "Episode: 832 Total reward: 50.0 Training loss: 0.5657 Explore P: 0.0409\n",
      "Episode: 833 Total reward: 63.0 Training loss: 175.6574 Explore P: 0.0407\n",
      "Episode: 834 Total reward: 94.0 Training loss: 0.6995 Explore P: 0.0404\n",
      "Episode: 835 Total reward: 67.0 Training loss: 1.0747 Explore P: 0.0402\n",
      "Episode: 836 Total reward: 86.0 Training loss: 0.3819 Explore P: 0.0400\n",
      "Episode: 837 Total reward: 81.0 Training loss: 0.6901 Explore P: 0.0397\n",
      "Episode: 838 Total reward: 117.0 Training loss: 0.4650 Explore P: 0.0394\n",
      "Episode: 839 Total reward: 89.0 Training loss: 0.7353 Explore P: 0.0391\n",
      "Episode: 841 Total reward: 78.0 Training loss: 0.5430 Explore P: 0.0383\n",
      "Episode: 844 Total reward: 99.0 Training loss: 0.7135 Explore P: 0.0370\n",
      "Episode: 845 Total reward: 112.0 Training loss: 125.8393 Explore P: 0.0367\n",
      "Episode: 848 Total reward: 99.0 Training loss: 0.5380 Explore P: 0.0354\n",
      "Episode: 849 Total reward: 130.0 Training loss: 0.5177 Explore P: 0.0350\n",
      "Episode: 851 Total reward: 115.0 Training loss: 0.5126 Explore P: 0.0343\n",
      "Episode: 852 Total reward: 125.0 Training loss: 0.8227 Explore P: 0.0340\n",
      "Episode: 853 Total reward: 142.0 Training loss: 1.2076 Explore P: 0.0336\n",
      "Episode: 854 Total reward: 186.0 Training loss: 1.0182 Explore P: 0.0332\n",
      "Episode: 856 Total reward: 9.0 Training loss: 102.8159 Explore P: 0.0327\n",
      "Episode: 857 Total reward: 107.0 Training loss: 0.8537 Explore P: 0.0325\n",
      "Episode: 858 Total reward: 126.0 Training loss: 0.4198 Explore P: 0.0322\n",
      "Episode: 859 Total reward: 162.0 Training loss: 97.1136 Explore P: 0.0318\n",
      "Episode: 860 Total reward: 114.0 Training loss: 0.5345 Explore P: 0.0316\n",
      "Episode: 861 Total reward: 176.0 Training loss: 0.3919 Explore P: 0.0312\n",
      "Episode: 862 Total reward: 110.0 Training loss: 0.4629 Explore P: 0.0310\n",
      "Episode: 863 Total reward: 129.0 Training loss: 0.4929 Explore P: 0.0307\n",
      "Episode: 864 Total reward: 114.0 Training loss: 77.0144 Explore P: 0.0305\n",
      "Episode: 865 Total reward: 111.0 Training loss: 0.4202 Explore P: 0.0302\n",
      "Episode: 866 Total reward: 111.0 Training loss: 0.5731 Explore P: 0.0300\n",
      "Episode: 867 Total reward: 123.0 Training loss: 0.5953 Explore P: 0.0298\n",
      "Episode: 868 Total reward: 128.0 Training loss: 0.6807 Explore P: 0.0295\n",
      "Episode: 869 Total reward: 103.0 Training loss: 0.7201 Explore P: 0.0293\n",
      "Episode: 870 Total reward: 101.0 Training loss: 0.6051 Explore P: 0.0291\n",
      "Episode: 871 Total reward: 132.0 Training loss: 0.5539 Explore P: 0.0289\n",
      "Episode: 872 Total reward: 115.0 Training loss: 0.5005 Explore P: 0.0287\n",
      "Episode: 873 Total reward: 121.0 Training loss: 0.5737 Explore P: 0.0284\n",
      "Episode: 874 Total reward: 120.0 Training loss: 0.8714 Explore P: 0.0282\n",
      "Episode: 875 Total reward: 16.0 Training loss: 0.6406 Explore P: 0.0282\n",
      "Episode: 876 Total reward: 34.0 Training loss: 67.2817 Explore P: 0.0281\n",
      "Episode: 877 Total reward: 109.0 Training loss: 0.5022 Explore P: 0.0279\n",
      "Episode: 878 Total reward: 104.0 Training loss: 69.1712 Explore P: 0.0277\n",
      "Episode: 879 Total reward: 96.0 Training loss: 0.4481 Explore P: 0.0276\n",
      "Episode: 880 Total reward: 42.0 Training loss: 0.7529 Explore P: 0.0275\n",
      "Episode: 881 Total reward: 96.0 Training loss: 0.5640 Explore P: 0.0273\n",
      "Episode: 882 Total reward: 106.0 Training loss: 0.3865 Explore P: 0.0271\n",
      "Episode: 883 Total reward: 24.0 Training loss: 0.7999 Explore P: 0.0271\n",
      "Episode: 884 Total reward: 111.0 Training loss: 61.3480 Explore P: 0.0269\n",
      "Episode: 885 Total reward: 21.0 Training loss: 0.9659 Explore P: 0.0269\n",
      "Episode: 886 Total reward: 19.0 Training loss: 1.1835 Explore P: 0.0269\n",
      "Episode: 887 Total reward: 27.0 Training loss: 49.9394 Explore P: 0.0268\n",
      "Episode: 888 Total reward: 24.0 Training loss: 67.0643 Explore P: 0.0268\n",
      "Episode: 889 Total reward: 93.0 Training loss: 1.4087 Explore P: 0.0266\n",
      "Episode: 890 Total reward: 16.0 Training loss: 0.9806 Explore P: 0.0266\n",
      "Episode: 891 Total reward: 25.0 Training loss: 0.9645 Explore P: 0.0265\n",
      "Episode: 892 Total reward: 17.0 Training loss: 1.2582 Explore P: 0.0265\n",
      "Episode: 893 Total reward: 19.0 Training loss: 0.6401 Explore P: 0.0265\n",
      "Episode: 894 Total reward: 22.0 Training loss: 0.9294 Explore P: 0.0264\n",
      "Episode: 895 Total reward: 18.0 Training loss: 0.9399 Explore P: 0.0264\n",
      "Episode: 896 Total reward: 19.0 Training loss: 0.5467 Explore P: 0.0264\n",
      "Episode: 897 Total reward: 31.0 Training loss: 0.6784 Explore P: 0.0263\n",
      "Episode: 898 Total reward: 97.0 Training loss: 0.6220 Explore P: 0.0262\n",
      "Episode: 899 Total reward: 106.0 Training loss: 0.4820 Explore P: 0.0260\n",
      "Episode: 900 Total reward: 107.0 Training loss: 0.8038 Explore P: 0.0258\n",
      "Episode: 901 Total reward: 27.0 Training loss: 0.7051 Explore P: 0.0258\n",
      "Episode: 902 Total reward: 99.0 Training loss: 0.4473 Explore P: 0.0256\n",
      "Episode: 903 Total reward: 102.0 Training loss: 0.7308 Explore P: 0.0255\n",
      "Episode: 904 Total reward: 117.0 Training loss: 0.6605 Explore P: 0.0253\n",
      "Episode: 905 Total reward: 112.0 Training loss: 0.2697 Explore P: 0.0251\n",
      "Episode: 906 Total reward: 139.0 Training loss: 0.3633 Explore P: 0.0249\n",
      "Episode: 907 Total reward: 149.0 Training loss: 0.5131 Explore P: 0.0247\n",
      "Episode: 908 Total reward: 112.0 Training loss: 0.5597 Explore P: 0.0245\n",
      "Episode: 909 Total reward: 123.0 Training loss: 42.8494 Explore P: 0.0244\n",
      "Episode: 910 Total reward: 109.0 Training loss: 0.9362 Explore P: 0.0242\n",
      "Episode: 911 Total reward: 118.0 Training loss: 52.7078 Explore P: 0.0240\n",
      "Episode: 912 Total reward: 125.0 Training loss: 0.5041 Explore P: 0.0239\n",
      "Episode: 913 Total reward: 131.0 Training loss: 0.6687 Explore P: 0.0237\n",
      "Episode: 914 Total reward: 123.0 Training loss: 0.7162 Explore P: 0.0235\n",
      "Episode: 915 Total reward: 117.0 Training loss: 0.4968 Explore P: 0.0234\n",
      "Episode: 916 Total reward: 119.0 Training loss: 0.7529 Explore P: 0.0232\n",
      "Episode: 917 Total reward: 129.0 Training loss: 0.4604 Explore P: 0.0230\n",
      "Episode: 918 Total reward: 135.0 Training loss: 0.5202 Explore P: 0.0229\n",
      "Episode: 919 Total reward: 149.0 Training loss: 0.2457 Explore P: 0.0227\n",
      "Episode: 920 Total reward: 195.0 Training loss: 0.4621 Explore P: 0.0224\n",
      "Episode: 922 Total reward: 31.0 Training loss: 0.4171 Explore P: 0.0221\n",
      "Episode: 924 Total reward: 182.0 Training loss: 0.5350 Explore P: 0.0217\n",
      "Episode: 927 Total reward: 4.0 Training loss: 45.2931 Explore P: 0.0212\n",
      "Episode: 929 Total reward: 171.0 Training loss: 0.4229 Explore P: 0.0208\n",
      "Episode: 931 Total reward: 144.0 Training loss: 0.3245 Explore P: 0.0204\n",
      "Episode: 933 Total reward: 48.0 Training loss: 63.4790 Explore P: 0.0202\n",
      "Episode: 935 Total reward: 67.0 Training loss: 0.4276 Explore P: 0.0199\n",
      "Episode: 936 Total reward: 194.0 Training loss: 0.9138 Explore P: 0.0197\n",
      "Episode: 937 Total reward: 123.0 Training loss: 0.6600 Explore P: 0.0196\n",
      "Episode: 938 Total reward: 114.0 Training loss: 100.3365 Explore P: 0.0195\n",
      "Episode: 939 Total reward: 119.0 Training loss: 1.2051 Explore P: 0.0194\n",
      "Episode: 940 Total reward: 32.0 Training loss: 1.1824 Explore P: 0.0194\n",
      "Episode: 941 Total reward: 60.0 Training loss: 1.2961 Explore P: 0.0193\n",
      "Episode: 942 Total reward: 19.0 Training loss: 0.6840 Explore P: 0.0193\n",
      "Episode: 943 Total reward: 21.0 Training loss: 1.4016 Explore P: 0.0193\n",
      "Episode: 944 Total reward: 20.0 Training loss: 302.1440 Explore P: 0.0192\n",
      "Episode: 945 Total reward: 20.0 Training loss: 0.7765 Explore P: 0.0192\n",
      "Episode: 946 Total reward: 19.0 Training loss: 1.2718 Explore P: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 947 Total reward: 115.0 Training loss: 0.5993 Explore P: 0.0191\n",
      "Episode: 948 Total reward: 54.0 Training loss: 1.1603 Explore P: 0.0191\n",
      "Episode: 949 Total reward: 113.0 Training loss: 0.8753 Explore P: 0.0190\n",
      "Episode: 950 Total reward: 161.0 Training loss: 0.9407 Explore P: 0.0188\n",
      "Episode: 951 Total reward: 152.0 Training loss: 1.6525 Explore P: 0.0187\n",
      "Episode: 952 Total reward: 131.0 Training loss: 0.7709 Explore P: 0.0186\n",
      "Episode: 953 Total reward: 112.0 Training loss: 363.4548 Explore P: 0.0185\n",
      "Episode: 954 Total reward: 123.0 Training loss: 1.0018 Explore P: 0.0184\n",
      "Episode: 955 Total reward: 158.0 Training loss: 1.1861 Explore P: 0.0182\n",
      "Episode: 956 Total reward: 163.0 Training loss: 0.6072 Explore P: 0.0181\n",
      "Episode: 957 Total reward: 162.0 Training loss: 0.9625 Explore P: 0.0180\n",
      "Episode: 959 Total reward: 5.0 Training loss: 0.5139 Explore P: 0.0178\n",
      "Episode: 962 Total reward: 99.0 Training loss: 0.6187 Explore P: 0.0174\n",
      "Episode: 965 Total reward: 99.0 Training loss: 0.6793 Explore P: 0.0171\n",
      "Episode: 968 Total reward: 99.0 Training loss: 2.3172 Explore P: 0.0167\n",
      "Episode: 970 Total reward: 47.0 Training loss: 2.0536 Explore P: 0.0166\n",
      "Episode: 973 Total reward: 87.0 Training loss: 1.6468 Explore P: 0.0162\n",
      "Episode: 976 Total reward: 69.0 Training loss: 0.6764 Explore P: 0.0160\n",
      "Episode: 979 Total reward: 99.0 Training loss: 1.1852 Explore P: 0.0157\n",
      "Episode: 981 Total reward: 142.0 Training loss: 1.3169 Explore P: 0.0155\n",
      "Episode: 983 Total reward: 53.0 Training loss: 1.4832 Explore P: 0.0153\n",
      "Episode: 984 Total reward: 168.0 Training loss: 2.7617 Explore P: 0.0153\n",
      "Episode: 985 Total reward: 174.0 Training loss: 2.8583 Explore P: 0.0152\n",
      "Episode: 986 Total reward: 144.0 Training loss: 3.6113 Explore P: 0.0151\n",
      "Episode: 987 Total reward: 160.0 Training loss: 1.5647 Explore P: 0.0150\n",
      "Episode: 988 Total reward: 138.0 Training loss: 3.3391 Explore P: 0.0149\n",
      "Episode: 989 Total reward: 21.0 Training loss: 125.7353 Explore P: 0.0149\n",
      "Episode: 990 Total reward: 20.0 Training loss: 5.1881 Explore P: 0.0149\n",
      "Episode: 991 Total reward: 115.0 Training loss: 3.9393 Explore P: 0.0149\n",
      "Episode: 992 Total reward: 19.0 Training loss: 3.1854 Explore P: 0.0149\n",
      "Episode: 993 Total reward: 20.0 Training loss: 2.6301 Explore P: 0.0148\n",
      "Episode: 994 Total reward: 16.0 Training loss: 3.1179 Explore P: 0.0148\n",
      "Episode: 995 Total reward: 15.0 Training loss: 1247.1318 Explore P: 0.0148\n",
      "Episode: 996 Total reward: 14.0 Training loss: 2.8885 Explore P: 0.0148\n",
      "Episode: 997 Total reward: 17.0 Training loss: 2.7933 Explore P: 0.0148\n",
      "Episode: 998 Total reward: 16.0 Training loss: 3.9300 Explore P: 0.0148\n",
      "Episode: 999 Total reward: 21.0 Training loss: 1.2854 Explore P: 0.0148\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "            \n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "            \n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "        \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below we plot the total rewards for each episode. The rolling average is plotted in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total Reward')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbad31aa438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Atari Games\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
